{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice, combinations, product\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "from collections import defaultdict\n",
    "from scipy.stats import hypergeom\n",
    "from collections import Counter\n",
    "from goatools import obo_parser\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"/home/clusterduck123/Desktop/git/supplements/data\"\n",
    "RAW_DATA_DIRECTORY = f\"{DATA_DIRECTORY}/raw-data\"\n",
    "YEAST_DIRECTORY = f\"{DATA_DIRECTORY}/processed-data/organisms/yeast\"\n",
    "NETWORK_DIRECTORY = f\"{YEAST_DIRECTORY}/networks\"\n",
    "ANNOTATION_DIRECTORY = f\"{YEAST_DIRECTORY}/annotations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and parse annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/clusterduck123/Desktop/git/supplements/data/raw-data/go-basic.obo: fmt(1.2) rel(2019-10-07) 47,285 GO Terms\n"
     ]
    }
   ],
   "source": [
    "namespace = 'CC'\n",
    "PPI = nx.read_edgelist(f\"{NETWORK_DIRECTORY}/PPI_BioGRID.txt\")\n",
    "annotation_df = pd.read_csv(f\"{ANNOTATION_DIRECTORY}/GO_{namespace}_BioGRID-SGD.csv\")\n",
    "go_dag = obo_parser.GODag(f\"{RAW_DATA_DIRECTORY}/go-basic.obo\")\n",
    "\n",
    "gene_population = set(PPI.nodes())\n",
    "GO_population = set(annotation_df.GO_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define convenient dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion dictionaries\n",
    "GO2genes = pd.Series({go_id: set(genes.Systematic_ID) for go_id, genes in annotation_df.groupby('GO_ID')}, \n",
    "                     name='nb_genes')\n",
    "\n",
    "gene2GO  = {gene : set(go_ids.GO_ID) for gene, go_ids in annotation_df.groupby('Systematic_ID')}\n",
    "global_GO_counter = GO2genes.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we GO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parser fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, n_clusters = 99):\n",
    "    splitted_file_names = [name.split('_') for name in os.listdir(CLUSTER_DIRECTORY)]\n",
    "    pre_runs = [int(run) for run, ncluster, db_txt in splitted_file_names if ncluster == str(n_clusters)]\n",
    "    if pre_runs:\n",
    "        return max(pre_runs)+1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster2GO(cluster):\n",
    "    return set.union(*(gene2GO.get(gene, set()) for gene in cluster))\n",
    "\n",
    "def is_annotated_in(gene, GO_set):\n",
    "    return not gene2GO.get(gene,set()).isdisjoint(GO_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 30\n",
    "\n",
    "all_distances = [filename.split('_')[0] for filename in os.listdir(f\"{YEAST_DIRECTORY}/distance-matrices/GDV\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mahalanobis\n",
      "29_99: 1040.98sec\n",
      "euclidean\n",
      "29_99: 1094.55sec\n",
      "GDV-similarity\n",
      "29_99: 1019.49sec\n",
      "chebyshev\n",
      "29_99: 1094.03sec\n",
      "normalized1-l2\n",
      "29_99: 1018.93sec\n",
      "cosine\n",
      "29_99: 1052.53sec\n",
      "correlation\n",
      "29_99: 1049.95sec\n",
      "seuclidean\n",
      "29_99: 1055.33sec\n",
      "normalized1-l1\n",
      "29_99: 1022.06sec\n",
      "canberra\n",
      "29_99: 1025.59sec\n",
      "cityblock\n",
      "29_99: 1084.59sec\n",
      "normalized1-linf\n",
      "29_99: 1002.50sec\n",
      "sqeuclidean\n",
      "29_99: 1085.69sec\n",
      "braycurtis\n",
      "29_99: 1156.95sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in all_distances:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(distance)\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GDV/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/enrichments/GDV/{distance}/{method}/{namespace}\"\n",
    "    \n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "    \n",
    "    runs = min(get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO2genes.index,\n",
    "                                                       columns = range(nb_clusters))\n",
    "\n",
    "            \n",
    "            k = nb_annotated_genes_in_cluster\n",
    "            \n",
    "            K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "            K.columns = k.columns\n",
    "            \n",
    "            n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "            n.index = k.index\n",
    "            \n",
    "            N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "            \n",
    "            assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "            assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "            \n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)\n",
    "            p_values.to_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\")\n",
    "            t2 = time.time()\n",
    "            print(f'{run}_{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCV-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 1\n",
    "\n",
    "all_distances = [filename.split('_')[0] for filename in os.listdir(f\"{YEAST_DIRECTORY}/distance-matrices/GCV-A\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all2_normalized1-l1\n",
      "0_99: 33.73sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in ['all2_normalized1-l1']:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(distance)\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GCV-A/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/enrichments/GCV-A/{distance}/{method}/{namespace}\"\n",
    "    \n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "    \n",
    "    runs = min(get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO2genes.index,\n",
    "                                                       columns = range(nb_clusters))\n",
    "\n",
    "            \n",
    "            k = nb_annotated_genes_in_cluster\n",
    "            \n",
    "            K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "            K.columns = k.columns\n",
    "            \n",
    "            n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "            n.index = k.index\n",
    "            \n",
    "            N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "            \n",
    "            assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "            assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "            \n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)\n",
    "            p_values.to_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\")\n",
    "            t2 = time.time()\n",
    "            print(f'{run}_{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graco",
   "language": "python",
   "name": "graco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
