{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice, combinations, product\n",
    "from collections import defaultdict\n",
    "from goatools import obo_parser\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set()\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "DATA_DIRECTORY = \"/media/clusterduck123/joe/data\"\n",
    "RAW_DATA_DIRECTORY = f\"{DATA_DIRECTORY}/raw-data\"\n",
    "YEAST_DIRECTORY = f\"{DATA_DIRECTORY}/processed-data/yeast\"\n",
    "NETWORK_DIRECTORY = f\"{YEAST_DIRECTORY}/networks\"\n",
    "MATRIX_DIRECTORY  = f\"{YEAST_DIRECTORY}/distance-matrices\"\n",
    "ANNOTATION_DIRECTORY  = f\"{YEAST_DIRECTORY}/annotations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect = 'MF'\n",
    "correction = 'BY'\n",
    "\n",
    "alpha = 0.05\n",
    "lb_GO = 5\n",
    "ub_GO = 500\n",
    "min_lvl = 0\n",
    "max_lvl = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/clusterduck123/joe/data/raw-data/go-basic.obo: fmt(1.2) rel(2019-10-07) 47,285 GO Terms\n"
     ]
    }
   ],
   "source": [
    "PPI = nx.read_edgelist(f\"{NETWORK_DIRECTORY}/PPI_BioGRID.txt\")\n",
    "\n",
    "annotation_df = pd.read_csv(f\"{ANNOTATION_DIRECTORY}/GO_{aspect}_BioGRID-SGD.csv\")\n",
    "\n",
    "go_dag = obo_parser.GODag(f\"{RAW_DATA_DIRECTORY}/go-basic.obo\")\n",
    "\n",
    "gene_population = set(PPI.nodes())\n",
    "GO_population = {go_id for go_id in set(annotation_df.GO_ID) \n",
    "                           if (lb_GO <= len(annotation_df[annotation_df.GO_ID == go_id]) <= ub_GO and\n",
    "                               min_lvl <= go_dag[go_id].level <= max_lvl)}\n",
    "\n",
    "annotation_df = annotation_df[annotation_df.GO_ID.isin(GO_population)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion dictionaries\n",
    "GO2genes = pd.Series({go_id: set(genes.Systematic_ID) for go_id, genes in annotation_df.groupby('GO_ID')}, \n",
    "                     name='nb_genes')\n",
    "gene2GO = defaultdict(set)\n",
    "gene2GO  = {gene : set(go_ids.GO_ID)        for gene, go_ids in annotation_df.groupby('Systematic_ID')}\n",
    "global_GO_counter = GO2genes.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_pre_runs(PVALUE_DIRECTORY, n_clusters = 99):\n",
    "    splitted_file_names = [name.split('_') for name in os.listdir(PVALUE_DIRECTORY)]\n",
    "    pre_runs = [int(run) for run, ncluster, db_txt in splitted_file_names if ncluster == str(n_clusters)]\n",
    "    if pre_runs:\n",
    "        return max(pre_runs)+1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enrichments(alpha, p_values, cluster_list, correction):\n",
    "    relevant_p_values = [p_values[str(cluster_idx)][cluster2GO(cluster)] \n",
    "                             for cluster_idx,cluster in enumerate(cluster_list)] \n",
    "    \n",
    "    sorted_p_values = sorted(p for p_cluster in relevant_p_values\n",
    "                               for p in p_cluster)\n",
    "    m = len(sorted_p_values)\n",
    "    if   correction == 'BY':\n",
    "        c = np.log(m) + np.euler_gamma + 1/(2*m)\n",
    "    elif correction == 'BH':\n",
    "        c = 1\n",
    "    else:\n",
    "        print(\"Correction not known!\")\n",
    "        raise Exception\n",
    "    for k,P_k in enumerate(sorted_p_values,1):\n",
    "        if P_k > k/(m*c) * alpha:\n",
    "            break\n",
    "    threshold = sorted_p_values[k-2]\n",
    "    return p_values < threshold\n",
    "\n",
    "\n",
    "def cluster2GO(cluster):\n",
    "    return set.union(*(gene2GO.get(gene, set()) for gene in cluster))\n",
    "\n",
    "def is_annotated_in(gene, GO_set):\n",
    "    return not gene2GO.get(gene,set()).isdisjoint(GO_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages = {}\n",
    "GO_coverages      = {}\n",
    "gene_coverages    = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 99\n",
    "MAX_RUNS     = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages['GDV'] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     'GDV'] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   'GDV'] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDV_similarity 0\n",
      "GDV_similarity 1\n",
      "GDV_similarity 2\n",
      "GDV_similarity 3\n",
      "GDV_similarity 4\n",
      "GDV_similarity 5\n",
      "GDV_similarity 6\n",
      "98: 9.90sec\n",
      "mahalanobis 0\n",
      "mahalanobis 1\n",
      "mahalanobis 2\n",
      "mahalanobis 3\n",
      "mahalanobis 4\n",
      "mahalanobis 5\n",
      "98: 9.81sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in ['GDV_similarity', 'mahalanobis']:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GDV/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/GDV/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages['GDV'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS)) \n",
    "        GO_coverages[     'GDV'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS))\n",
    "        gene_coverages[   'GDV'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages['GDV'][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     'GDV'][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   'GDV'][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/GDV/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages['GDV'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     'GDV'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   'GDV'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages['GCV-A'] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     'GCV-A'] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   'GCV-A'] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized1-l1 0\n",
      "normalized1-l1 1\n",
      "normalized1-l1 2\n",
      "normalized1-l1 3\n",
      "normalized1-l1 4\n",
      "normalized1-l1 5\n",
      "normalized1-l1 6\n",
      "normalized1-l1 7\n",
      "normalized1-l1 8\n",
      "normalized1-l1 9\n",
      "normalized1-l1 10\n",
      "normalized1-l1 11\n",
      "normalized1-l1 12\n",
      "normalized1-l1 13\n",
      "normalized1-l1 14\n",
      "normalized1-l1 15\n",
      "normalized1-l1 16\n",
      "normalized1-l1 17\n",
      "normalized1-l1 18\n",
      "normalized1-l1 19\n",
      "normalized1-l1 20\n",
      "normalized1-l1 21\n",
      "normalized1-l1 22\n",
      "normalized1-l1 23\n",
      "normalized1-l1 24\n",
      "normalized1-l1 25\n",
      "normalized1-l1 26\n",
      "normalized1-l1 27\n",
      "normalized1-l1 28\n",
      "normalized1-l1 29\n",
      "98: 10.42sec\n",
      "normalized1-l2 0\n",
      "normalized1-l2 1\n",
      "normalized1-l2 2\n",
      "normalized1-l2 3\n",
      "normalized1-l2 4\n",
      "normalized1-l2 5\n",
      "normalized1-l2 6\n",
      "normalized1-l2 7\n",
      "normalized1-l2 8\n",
      "normalized1-l2 9\n",
      "normalized1-l2 10\n",
      "normalized1-l2 11\n",
      "normalized1-l2 12\n",
      "normalized1-l2 13\n",
      "normalized1-l2 14\n",
      "normalized1-l2 15\n",
      "normalized1-l2 16\n",
      "normalized1-l2 17\n",
      "normalized1-l2 18\n",
      "normalized1-l2 19\n",
      "normalized1-l2 20\n",
      "normalized1-l2 21\n",
      "normalized1-l2 22\n",
      "normalized1-l2 23\n",
      "normalized1-l2 24\n",
      "normalized1-l2 25\n",
      "normalized1-l2 26\n",
      "normalized1-l2 27\n",
      "normalized1-l2 28\n",
      "normalized1-l2 29\n",
      "98: 10.39sec\n",
      "normalized1-linf 0\n",
      "normalized1-linf 1\n",
      "normalized1-linf 2\n",
      "normalized1-linf 3\n",
      "normalized1-linf 4\n",
      "normalized1-linf 5\n",
      "normalized1-linf 6\n",
      "normalized1-linf 7\n",
      "normalized1-linf 8\n",
      "normalized1-linf 9\n",
      "normalized1-linf 10\n",
      "normalized1-linf 11\n",
      "normalized1-linf 12\n",
      "normalized1-linf 13\n",
      "normalized1-linf 14\n",
      "normalized1-linf 15\n",
      "normalized1-linf 16\n",
      "normalized1-linf 17\n",
      "normalized1-linf 18\n",
      "normalized1-linf 19\n",
      "normalized1-linf 20\n",
      "normalized1-linf 21\n",
      "normalized1-linf 22\n",
      "normalized1-linf 23\n",
      "normalized1-linf 24\n",
      "normalized1-linf 25\n",
      "normalized1-linf 26\n",
      "normalized1-linf 27\n",
      "normalized1-linf 28\n",
      "normalized1-linf 29\n",
      "98: 10.35sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in [\n",
    "                 'normalized1-l1',\n",
    "                 'normalized1-l2',\n",
    "                 'normalized1-linf'\n",
    "                ]:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GCV-A/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/GCV-A/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages['GCV-A'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     'GCV-A'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   'GCV-A'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages['GCV-A'][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     'GCV-A'][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   'GCV-A'][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/GCV-A/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages['GCV-A'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     'GCV-A'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   'GCV-A'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCV-G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages['GCV-G'] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     'GCV-G'] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   'GCV-G'] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized1-l1 0\n",
      "normalized1-l1 1\n",
      "normalized1-l1 2\n",
      "normalized1-l1 3\n",
      "normalized1-l1 4\n",
      "normalized1-l1 5\n",
      "normalized1-l1 6\n",
      "normalized1-l1 7\n",
      "normalized1-l1 8\n",
      "normalized1-l1 9\n",
      "normalized1-l1 10\n",
      "normalized1-l1 11\n",
      "normalized1-l1 12\n",
      "normalized1-l1 13\n",
      "normalized1-l1 14\n",
      "normalized1-l1 15\n",
      "normalized1-l1 16\n",
      "normalized1-l1 17\n",
      "normalized1-l1 18\n",
      "normalized1-l1 19\n",
      "normalized1-l1 20\n",
      "normalized1-l1 21\n",
      "normalized1-l1 22\n",
      "normalized1-l1 23\n",
      "normalized1-l1 24\n",
      "normalized1-l1 25\n",
      "normalized1-l1 26\n",
      "normalized1-l1 27\n",
      "normalized1-l1 28\n",
      "normalized1-l1 29\n",
      "98: 10.39sec\n",
      "normalized1-l2 0\n",
      "normalized1-l2 1\n",
      "normalized1-l2 2\n",
      "normalized1-l2 3\n",
      "normalized1-l2 4\n",
      "normalized1-l2 5\n",
      "normalized1-l2 6\n",
      "normalized1-l2 7\n",
      "normalized1-l2 8\n",
      "normalized1-l2 9\n",
      "normalized1-l2 10\n",
      "normalized1-l2 11\n",
      "normalized1-l2 12\n",
      "normalized1-l2 13\n",
      "normalized1-l2 14\n",
      "normalized1-l2 15\n",
      "normalized1-l2 16\n",
      "normalized1-l2 17\n",
      "normalized1-l2 18\n",
      "normalized1-l2 19\n",
      "normalized1-l2 20\n",
      "normalized1-l2 21\n",
      "normalized1-l2 22\n",
      "normalized1-l2 23\n",
      "normalized1-l2 24\n",
      "normalized1-l2 25\n",
      "normalized1-l2 26\n",
      "normalized1-l2 27\n",
      "normalized1-l2 28\n",
      "normalized1-l2 29\n",
      "98: 10.38sec\n",
      "normalized1-linf 0\n",
      "normalized1-linf 1\n",
      "normalized1-linf 2\n",
      "normalized1-linf 3\n",
      "normalized1-linf 4\n",
      "normalized1-linf 5\n",
      "normalized1-linf 6\n",
      "normalized1-linf 7\n",
      "normalized1-linf 8\n",
      "normalized1-linf 9\n",
      "normalized1-linf 10\n",
      "normalized1-linf 11\n",
      "normalized1-linf 12\n",
      "normalized1-linf 13\n",
      "normalized1-linf 14\n",
      "normalized1-linf 15\n",
      "normalized1-linf 16\n",
      "normalized1-linf 17\n",
      "normalized1-linf 18\n",
      "normalized1-linf 19\n",
      "normalized1-linf 20\n",
      "normalized1-linf 21\n",
      "normalized1-linf 22\n",
      "normalized1-linf 23\n",
      "normalized1-linf 24\n",
      "normalized1-linf 25\n",
      "normalized1-linf 26\n",
      "normalized1-linf 27\n",
      "normalized1-linf 28\n",
      "normalized1-linf 29\n",
      "98: 10.44sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in [\n",
    "                 'normalized1-l1',\n",
    "                 'normalized1-l2',\n",
    "                 'normalized1-linf'\n",
    "                ]:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GCV-G/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/GCV-G/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages['GCV-G'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     'GCV-G'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   'GCV-G'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages['GCV-G'][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     'GCV-G'][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   'GCV-G'][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/GCV-G/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages['GCV-G'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     'GCV-G'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   'GCV-G'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCV-DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-DG'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages[feature] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     feature] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   feature] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "braycurtis 0\n",
      "braycurtis 1\n",
      "braycurtis 2\n",
      "braycurtis 3\n",
      "braycurtis 4\n",
      "braycurtis 5\n",
      "braycurtis 6\n",
      "braycurtis 7\n",
      "braycurtis 8\n",
      "braycurtis 9\n",
      "braycurtis 10\n",
      "braycurtis 11\n",
      "braycurtis 12\n",
      "braycurtis 13\n",
      "braycurtis 14\n",
      "braycurtis 15\n",
      "braycurtis 16\n",
      "braycurtis 17\n",
      "braycurtis 18\n",
      "braycurtis 19\n",
      "braycurtis 20\n",
      "braycurtis 21\n",
      "braycurtis 22\n",
      "braycurtis 23\n",
      "braycurtis 24\n",
      "braycurtis 25\n",
      "braycurtis 26\n",
      "braycurtis 27\n",
      "braycurtis 28\n",
      "98: 8.01sec\n",
      "canberra 0\n",
      "canberra 1c\n",
      "canberra 2c\n",
      "canberra 3c\n",
      "canberra 4c\n",
      "canberra 5c\n",
      "canberra 6c\n",
      "canberra 7c\n",
      "canberra 8c\n",
      "canberra 9c\n",
      "canberra 10\n",
      "canberra 11\n",
      "canberra 12\n",
      "canberra 13\n",
      "canberra 14\n",
      "canberra 15\n",
      "canberra 16\n",
      "canberra 17\n",
      "canberra 18\n",
      "canberra 19\n",
      "canberra 20\n",
      "canberra 21\n",
      "canberra 22\n",
      "canberra 23\n",
      "canberra 24\n",
      "canberra 25\n",
      "canberra 26\n",
      "canberra 27\n",
      "canberra 28\n",
      "98: 8.30sec\n",
      "chebyshev 0\n",
      "chebyshev 1\n",
      "chebyshev 2\n",
      "chebyshev 3\n",
      "chebyshev 4\n",
      "chebyshev 5\n",
      "chebyshev 6\n",
      "chebyshev 7\n",
      "chebyshev 8\n",
      "chebyshev 9\n",
      "chebyshev 10\n",
      "chebyshev 11\n",
      "chebyshev 12\n",
      "chebyshev 13\n",
      "chebyshev 14\n",
      "chebyshev 15\n",
      "chebyshev 16\n",
      "chebyshev 17\n",
      "chebyshev 18\n",
      "chebyshev 19\n",
      "chebyshev 20\n",
      "chebyshev 21\n",
      "chebyshev 22\n",
      "chebyshev 23\n",
      "chebyshev 24\n",
      "chebyshev 25\n",
      "chebyshev 26\n",
      "chebyshev 27\n",
      "chebyshev 28\n",
      "98: 7.97sec\n",
      "cityblock 0\n",
      "cityblock 1\n",
      "cityblock 2\n",
      "cityblock 3\n",
      "cityblock 4\n",
      "cityblock 5\n",
      "cityblock 6\n",
      "cityblock 7\n",
      "cityblock 8\n",
      "cityblock 9\n",
      "cityblock 10\n",
      "cityblock 11\n",
      "cityblock 12\n",
      "cityblock 13\n",
      "cityblock 14\n",
      "cityblock 15\n",
      "cityblock 16\n",
      "cityblock 17\n",
      "cityblock 18\n",
      "cityblock 19\n",
      "cityblock 20\n",
      "cityblock 21\n",
      "cityblock 22\n",
      "cityblock 23\n",
      "cityblock 24\n",
      "cityblock 25\n",
      "cityblock 26\n",
      "cityblock 27\n",
      "cityblock 28\n",
      "98: 7.80sec\n",
      "correlation 0\n",
      "correlation 1\n",
      "correlation 2\n",
      "correlation 3\n",
      "correlation 4\n",
      "correlation 5\n",
      "correlation 6\n",
      "correlation 7\n",
      "correlation 8\n",
      "correlation 9\n",
      "98: 7.53sec\n",
      "cosine 0\n",
      "cosine 1sec\n",
      "cosine 2sec\n",
      "cosine 3sec\n",
      "cosine 4sec\n",
      "cosine 5sec\n",
      "cosine 6sec\n",
      "cosine 7sec\n",
      "cosine 8sec\n",
      "cosine 9sec\n",
      "98: 7.88sec\n",
      "euclidean 0\n",
      "euclidean 1\n",
      "euclidean 2\n",
      "euclidean 3\n",
      "euclidean 4\n",
      "euclidean 5\n",
      "euclidean 6\n",
      "euclidean 7\n",
      "euclidean 8\n",
      "euclidean 9\n",
      "98: 7.82sec\n",
      "hellinger 0\n",
      "hellinger 1\n",
      "hellinger 2\n",
      "hellinger 3\n",
      "hellinger 4\n",
      "hellinger 5\n",
      "hellinger 6\n",
      "hellinger 7\n",
      "hellinger 8\n",
      "hellinger 9\n",
      "98: 7.95sec\n",
      "mahalanobis 0\n",
      "mahalanobis 1\n",
      "mahalanobis 2\n",
      "mahalanobis 3\n",
      "mahalanobis 4\n",
      "mahalanobis 5\n",
      "mahalanobis 6\n",
      "mahalanobis 7\n",
      "mahalanobis 8\n",
      "mahalanobis 9\n",
      "98: 7.78sec\n",
      "normalized1_l1 0\n",
      "normalized1_l1 1\n",
      "normalized1_l1 2\n",
      "normalized1_l1 3\n",
      "normalized1_l1 4\n",
      "normalized1_l1 5\n",
      "normalized1_l1 6\n",
      "normalized1_l1 7\n",
      "normalized1_l1 8\n",
      "normalized1_l1 9\n",
      "98: 8.06sec\n",
      "normalized1_l2 0\n",
      "normalized1_l2 1\n",
      "normalized1_l2 2\n",
      "normalized1_l2 3\n",
      "normalized1_l2 4\n",
      "normalized1_l2 5\n",
      "normalized1_l2 6\n",
      "normalized1_l2 7\n",
      "normalized1_l2 8\n",
      "normalized1_l2 9\n",
      "98: 8.00sec\n",
      "normalized1_linf 0\n",
      "normalized1_linf 1\n",
      "normalized1_linf 2\n",
      "normalized1_linf 3\n",
      "normalized1_linf 4\n",
      "normalized1_linf 5\n",
      "normalized1_linf 6\n",
      "normalized1_linf 7\n",
      "normalized1_linf 8\n",
      "normalized1_linf 9\n",
      "98: 7.76sec\n",
      "normalized2_l1 0\n",
      "normalized2_l1 1\n",
      "normalized2_l1 2\n",
      "normalized2_l1 3\n",
      "normalized2_l1 4\n",
      "normalized2_l1 5\n",
      "normalized2_l1 6\n",
      "normalized2_l1 7\n",
      "normalized2_l1 8\n",
      "normalized2_l1 9\n",
      "98: 8.20sec\n",
      "normalized2_l2 0\n",
      "normalized2_l2 1\n",
      "normalized2_l2 2\n",
      "normalized2_l2 3\n",
      "normalized2_l2 4\n",
      "normalized2_l2 5\n",
      "normalized2_l2 6\n",
      "normalized2_l2 7\n",
      "normalized2_l2 8\n",
      "normalized2_l2 9\n",
      "98: 7.95sec\n",
      "normalized2_linf 0\n",
      "normalized2_linf 1\n",
      "normalized2_linf 2\n",
      "normalized2_linf 3\n",
      "normalized2_linf 4\n",
      "normalized2_linf 5\n",
      "normalized2_linf 6\n",
      "normalized2_linf 7\n",
      "normalized2_linf 8\n",
      "normalized2_linf 9\n",
      "98: 8.02sec\n",
      "seuclidean 0\n",
      "seuclidean 1\n",
      "seuclidean 2\n",
      "seuclidean 3\n",
      "seuclidean 4\n",
      "seuclidean 5\n",
      "seuclidean 6\n",
      "seuclidean 7\n",
      "seuclidean 8\n",
      "seuclidean 9\n",
      "98: 8.22sec\n",
      "sqeuclidean 0\n",
      "sqeuclidean 1\n",
      "sqeuclidean 2\n",
      "sqeuclidean 3\n",
      "sqeuclidean 4\n",
      "sqeuclidean 5\n",
      "sqeuclidean 6\n",
      "sqeuclidean 7\n",
      "sqeuclidean 8\n",
      "sqeuclidean 9\n",
      "98: 7.96sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in all_distances:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages[feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages[feature][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     feature][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   feature][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/{feature}/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages[feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCV-AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages['GCV-AD'] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     'GCV-AD'] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   'GCV-AD'] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized1-l1 0\n",
      "normalized1-l1 1\n",
      "normalized1-l1 2\n",
      "normalized1-l1 3\n",
      "normalized1-l1 4\n",
      "normalized1-l1 5\n",
      "normalized1-l1 6\n",
      "normalized1-l1 7\n",
      "normalized1-l1 8\n",
      "normalized1-l1 9\n",
      "normalized1-l1 10\n",
      "normalized1-l1 11\n",
      "normalized1-l1 12\n",
      "normalized1-l1 13\n",
      "normalized1-l1 14\n",
      "normalized1-l1 15\n",
      "normalized1-l1 16\n",
      "normalized1-l1 17\n",
      "normalized1-l1 18\n",
      "normalized1-l1 19\n",
      "normalized1-l1 20\n",
      "normalized1-l1 21\n",
      "normalized1-l1 22\n",
      "normalized1-l1 23\n",
      "normalized1-l1 24\n",
      "normalized1-l1 25\n",
      "normalized1-l1 26\n",
      "normalized1-l1 27\n",
      "normalized1-l1 28\n",
      "normalized1-l1 29\n",
      "98: 10.21sec\n",
      "normalized1-l2 0\n",
      "normalized1-l2 1\n",
      "normalized1-l2 2\n",
      "normalized1-l2 3\n",
      "normalized1-l2 4\n",
      "normalized1-l2 5\n",
      "normalized1-l2 6\n",
      "normalized1-l2 7\n",
      "normalized1-l2 8\n",
      "normalized1-l2 9\n",
      "normalized1-l2 10\n",
      "normalized1-l2 11\n",
      "normalized1-l2 12\n",
      "normalized1-l2 13\n",
      "normalized1-l2 14\n",
      "normalized1-l2 15\n",
      "normalized1-l2 16\n",
      "normalized1-l2 17\n",
      "normalized1-l2 18\n",
      "normalized1-l2 19\n",
      "normalized1-l2 20\n",
      "normalized1-l2 21\n",
      "normalized1-l2 22\n",
      "normalized1-l2 23\n",
      "normalized1-l2 24\n",
      "normalized1-l2 25\n",
      "normalized1-l2 26\n",
      "normalized1-l2 27\n",
      "normalized1-l2 28\n",
      "normalized1-l2 29\n",
      "98: 10.28sec\n",
      "normalized1-linf 0\n",
      "normalized1-linf 1\n",
      "normalized1-linf 2\n",
      "normalized1-linf 3\n",
      "normalized1-linf 4\n",
      "normalized1-linf 5\n",
      "normalized1-linf 6\n",
      "normalized1-linf 7\n",
      "normalized1-linf 8\n",
      "normalized1-linf 9\n",
      "normalized1-linf 10\n",
      "normalized1-linf 11\n",
      "normalized1-linf 12\n",
      "normalized1-linf 13\n",
      "normalized1-linf 14\n",
      "normalized1-linf 15\n",
      "normalized1-linf 16\n",
      "normalized1-linf 17\n",
      "normalized1-linf 18\n",
      "normalized1-linf 19\n",
      "normalized1-linf 20\n",
      "normalized1-linf 21\n",
      "normalized1-linf 22\n",
      "normalized1-linf 23\n",
      "normalized1-linf 24\n",
      "normalized1-linf 25\n",
      "normalized1-linf 26\n",
      "normalized1-linf 27\n",
      "normalized1-linf 28\n",
      "normalized1-linf 29\n",
      "98: 10.42sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in [\n",
    "                 'normalized1-l1',\n",
    "                 'normalized1-l2',\n",
    "                 'normalized1-linf'\n",
    "                ]:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GCV-AD/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/GCV-AD/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages['GCV-AD'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     'GCV-AD'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   'GCV-AD'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages['GCV-AD'][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     'GCV-AD'][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   'GCV-AD'][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/GCV-AD/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages['GCV-AD'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     'GCV-AD'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   'GCV-AD'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-all1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-all1'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages[feature] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     feature] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   feature] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra 0\n",
      "canberra 1ec\n",
      "canberra 2ec\n",
      "canberra 3ec\n",
      "canberra 4ec\n",
      "98: 10.41sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra'}:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages[feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages[feature][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     feature][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   feature][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/{feature}/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages[feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-all2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-all2'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages[feature] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     feature] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   feature] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra 0\n",
      "canberra 1c\n",
      "49: 2.25sec\r"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra'}:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages[feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages[feature][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     feature][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   feature][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/{feature}/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages[feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-orca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-orca'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages[feature] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     feature] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   feature] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra 0\n",
      "canberra 1c\n",
      "canberra 2c\n",
      "canberra 3c\n",
      "canberra 4c\n",
      "canberra 5c\n",
      "canberra 6c\n",
      "canberra 7c\n",
      "canberra 8c\n",
      "canberra 9c\n",
      "98: 7.18sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra'}:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages[feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages[feature][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     feature][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   feature][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/{feature}/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages[feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graco",
   "language": "python",
   "name": "graco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
