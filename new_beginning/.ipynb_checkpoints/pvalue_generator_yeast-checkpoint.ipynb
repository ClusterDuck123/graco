{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice, combinations, product\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "from collections import defaultdict\n",
    "from scipy.stats import hypergeom\n",
    "from collections import Counter\n",
    "from goatools import obo_parser\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"/media/clusterduck123/joe/data\"\n",
    "RAW_DATA_DIRECTORY = f\"{DATA_DIRECTORY}/raw_data\"\n",
    "YEAST_DIRECTORY = f\"{DATA_DIRECTORY}/processed_data/yeast\"\n",
    "NETWORK_DIRECTORY = f\"{YEAST_DIRECTORY}/networks\"\n",
    "ANNOTATION_DIRECTORY = f\"{YEAST_DIRECTORY}/annotations\"\n",
    "MATRIX_DIRECTORY  = f\"{YEAST_DIRECTORY}/distance_matrices\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/usr/lib/python36.zip/input_parameters.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-22a3cb5c0b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# Input parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{sys.path[0]}/input_parameters.py\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/lib/python36.zip/input_parameters.py'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import multiprocessing\n",
    "\n",
    "\"\"\"\n",
    "Takes network, feature and metric as input and calculates distance matrix.\n",
    "\"\"\"\n",
    "# =============================================================================\n",
    "#  ---------------------------- GLOBAL PARAMETERS ----------------------------\n",
    "# =============================================================================\n",
    "\n",
    "RUN = 0\n",
    "MIN_CLUSTERS = 40\n",
    "MAX_CLUSTERS = 50\n",
    "\n",
    "# =============================================================================\n",
    "#  -------------------------------- FUNCTIONS --------------------------------\n",
    "# =============================================================================\n",
    "\n",
    "def cluster2GO(cluster):\n",
    "    return set.union(*(gene2GO.get(gene, set()) for gene in cluster))\n",
    "\n",
    "def is_annotated_in(gene, GO_set):\n",
    "    return not gene2GO.get(gene,set()).isdisjoint(GO_set)\n",
    "\n",
    "# =============================================================================\n",
    "#  ---------------------------------- MAIN -----------------------------------\n",
    "# =============================================================================\n",
    "\n",
    "def main(network, feature, metric, method):\n",
    "    print(multiprocessing.current_process().name)\n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{network}/{feature}/{metric}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/pvalues/{network}/{feature}/{metric}/{method}/{aspect}\"\n",
    "\n",
    "    G_nx = nx.read_edgelist(f\"{YEAST_DIRECTORY}/networks/{network}.txt\")\n",
    "    annotation_df = pd.read_csv(f\"{ANNOTATION_DIRECTORY}/GO_{aspect}_systematic_SGD.csv\")\n",
    "    annotation_df = annotation_df[annotation_df.Systematic_ID.isin(G_nx)]\n",
    "    go_dag = obo_parser.GODag(f\"{RAW_DATA_DIRECTORY}/go-basic.obo\")\n",
    "\n",
    "    GO_population = set(annotation_df.GO_ID)\n",
    "\n",
    "    # Conversion dictionaries\n",
    "    GO2genes = pd.Series({go_id: set(genes.Systematic_ID)\n",
    "                            for go_id, genes in annotation_df.groupby('GO_ID')},\n",
    "                         name='nb_genes')\n",
    "\n",
    "    gene2GO  = {gene : set(go_ids.GO_ID) for gene, go_ids in annotation_df.groupby('Systematic_ID')}\n",
    "    global_GO_counter = GO2genes.apply(len)\n",
    "\n",
    "    for n_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS+1):\n",
    "        with open(f\"{CLUSTER_DIRECTORY}/{RUN}_{n_clusters}.txt\", 'r') as f:\n",
    "             cluster_list = [set(line.split()) for line in f]\n",
    "        cluster_df = pd.Series({gene:cluster_idx\n",
    "                                    for cluster_idx,cluster in enumerate(cluster_list)\n",
    "                                    for gene in cluster})\n",
    "\n",
    "        n_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                   index   = GO2genes.index,\n",
    "                                                   columns = range(n_clusters))\n",
    "\n",
    "\n",
    "        k = n_annotated_genes_in_cluster\n",
    "\n",
    "        K = pd.concat([global_GO_counter[GO2genes.index]]*n_clusters, axis=1)\n",
    "        K.columns = k.columns\n",
    "\n",
    "        n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "        n.index = k.index\n",
    "\n",
    "        N = pd.DataFrame(len(G_nx), columns=k.columns, index=k.index)\n",
    "\n",
    "        assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "        assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "\n",
    "        # scipy has a really messed up nomeclature...\n",
    "        p_values = pd.DataFrame(1-hypergeom.cdf(k=k.values-1,\n",
    "                                                M=N.values,\n",
    "                                                N=n.values,\n",
    "                                                n=K.values),\n",
    "                                index=GO2genes.index)\n",
    "        p_values.to_csv(f\"{PVALUE_DIRECTORY}/{RUN}_{n_clusters}.txt\")\n",
    "\n",
    "        \n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "# Global constants\n",
    "\n",
    "DATA_DIRECTORY = \"/media/clusterduck123/joe/data/\"\n",
    "RAW_DATA_DIRECTORY = f\"{DATA_DIRECTORY}/raw_data\"\n",
    "YEAST_DIRECTORY = f\"{DATA_DIRECTORY}/processed_data/yeast\"\n",
    "ANNOTATION_DIRECTORY = f\"{YEAST_DIRECTORY}/annotations\"\n",
    "\n",
    "# Input parameters\n",
    "with open(f\"input_parameters.py\") as f:\n",
    "    for line in f:\n",
    "        exec(line.strip())\n",
    "\n",
    "\n",
    "# Define necessary directories\n",
    "for network, feature, metric, method, aspect in product(networks, features, metrics, methods, aspects):\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/pvalues/{network}/{feature}/{metric}/{method}/{aspect}\"\n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "\n",
    "with Pool(96) as p:\n",
    "    p.starmap(main,product(networks, features, metrics, methods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and parse annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/clusterduck123/joe/data/raw_data/go-basic.obo: fmt(1.2) rel(2019-10-07) 47,285 GO Terms\n"
     ]
    }
   ],
   "source": [
    "aspect  = 'BP'\n",
    "method  = 'kmedoid'\n",
    "network = 'systematic_CoEx_COEXPRESdb' \n",
    "\n",
    "PPI = nx.read_edgelist(f\"{NETWORK_DIRECTORY}/systematic_PPI_BioGRID.txt\")\n",
    "annotation_df = pd.read_csv(f\"{ANNOTATION_DIRECTORY}/GO_{aspect}_systematic_BioGRID-SGD.csv\")\n",
    "go_dag = obo_parser.GODag(f\"{RAW_DATA_DIRECTORY}/go-basic.obo\")\n",
    "\n",
    "gene_population = set(PPI.nodes())\n",
    "GO_population = set(annotation_df.GO_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define convenient dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion dictionaries\n",
    "GO2genes = pd.Series({go_id: set(genes.Systematic_ID) for go_id, genes in annotation_df.groupby('GO_ID')}, \n",
    "                     name='nb_genes')\n",
    "\n",
    "gene2GO  = {gene : set(go_ids.GO_ID) for gene, go_ids in annotation_df.groupby('Systematic_ID')}\n",
    "global_GO_counter = GO2genes.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we GO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parser fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, n_clusters = 99):\n",
    "    splitted_file_names = [name.split('_') for name in os.listdir(CLUSTER_DIRECTORY)]\n",
    "    pre_runs = [int(run) for run, ncluster in splitted_file_names if ncluster == str(n_clusters)]\n",
    "    if pre_runs:\n",
    "        return max(pre_runs)+1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster2GO(cluster):\n",
    "    return set.union(*(gene2GO.get(gene, set()) for gene in cluster))\n",
    "\n",
    "def is_annotated_in(gene, GO_set):\n",
    "    return not gene2GO.get(gene,set()).isdisjoint(GO_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'systematic_PPI_BioGRID'\n",
    "feature = 'GCV-O+'\n",
    "metric  = 'canberra'\n",
    "method  = 'kmedoid'\n",
    "aspect  = 'BP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{network}/{feature}/{metric}/{method}\"\n",
    "PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/p-values/{network}/{feature}/{metric}/{method}/{aspect}\"\n",
    "\n",
    "run = 3\n",
    "nb_clusters = 45\n",
    "\n",
    "with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}.txt\", 'r') as f:\n",
    "     cluster_list = [set(line.split()) for line in f]\n",
    "cluster_df = pd.Series({gene:cluster_idx \n",
    "                            for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                            for gene in cluster})\n",
    "\n",
    "nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "        [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                           index   = GO2genes.index,\n",
    "                                           columns = range(nb_clusters))\n",
    "\n",
    "\n",
    "k = nb_annotated_genes_in_cluster\n",
    "\n",
    "K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "K.columns = k.columns\n",
    "\n",
    "n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "n.index = k.index\n",
    "\n",
    "N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "\n",
    "assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "assert N.eq(n.sum(axis=1), axis=0).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values1 = pd.DataFrame(1-hypergeom.cdf(k=k.values-1, M=N.values, N=n.values, n=K.values), index=GO2genes.index)\n",
    "p_values2 = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GO:0000001</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0000002</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0000003</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0000011</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0000018</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:2001252</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:2001253</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:2001255</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:2001276</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:2001278</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4697 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0   1   2   3   4   5   6   7   8   9   ...  35  36  37  38  39  \\\n",
       "GO:0000001  22  22  22  22  22  22  22  22  22  22  ...  22  22  22  22  22   \n",
       "GO:0000002  36  36  36  36  36  36  36  36  36  36  ...  36  36  36  36  36   \n",
       "GO:0000003  41  41  41  41  41  41  41  41  41  41  ...  41  41  41  41  41   \n",
       "GO:0000011  16  16  16  16  16  16  16  16  16  16  ...  16  16  16  16  16   \n",
       "GO:0000018  29  29  29  29  29  29  29  29  29  29  ...  29  29  29  29  29   \n",
       "...         ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..   \n",
       "GO:2001252  36  36  36  36  36  36  36  36  36  36  ...  36  36  36  36  36   \n",
       "GO:2001253   3   3   3   3   3   3   3   3   3   3  ...   3   3   3   3   3   \n",
       "GO:2001255   3   3   3   3   3   3   3   3   3   3  ...   3   3   3   3   3   \n",
       "GO:2001276   1   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   1   \n",
       "GO:2001278   1   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   1   \n",
       "\n",
       "            40  41  42  43  44  \n",
       "GO:0000001  22  22  22  22  22  \n",
       "GO:0000002  36  36  36  36  36  \n",
       "GO:0000003  41  41  41  41  41  \n",
       "GO:0000011  16  16  16  16  16  \n",
       "GO:0000018  29  29  29  29  29  \n",
       "...         ..  ..  ..  ..  ..  \n",
       "GO:2001252  36  36  36  36  36  \n",
       "GO:2001253   3   3   3   3   3  \n",
       "GO:2001255   3   3   3   3   3  \n",
       "GO:2001276   1   1   1   1   1  \n",
       "GO:2001278   1   1   1   1   1  \n",
       "\n",
       "[4697 rows x 45 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/clusterduck123/joe/data/processed_data/yeast/distance_matrices/GCV-O+'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b527658d91f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m all_distances = sorted('_'.join(filename.split('_')[:-1]) \n\u001b[0;32m----> 4\u001b[0;31m                            for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/clusterduck123/joe/data/processed_data/yeast/distance_matrices/GCV-O+'"
     ]
    }
   ],
   "source": [
    "feature = 'GDV'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra\n",
      "\n",
      "mahalanobis\n",
      "\n",
      "GDV_similarity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for distance in {'GDV_similarity', 'canberra', 'mahalanobis'}:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(distance)\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{network}/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/p-values/{network}/{feature}/{distance}/{method}/{aspect}\"\n",
    "    \n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "    \n",
    "    runs = min(get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            if os.path.exists(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\"):\n",
    "                continue\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO2genes.index,\n",
    "                                                       columns = range(nb_clusters))\n",
    "\n",
    "            \n",
    "            k = nb_annotated_genes_in_cluster\n",
    "            \n",
    "            K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "            K.columns = k.columns\n",
    "            \n",
    "            n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "            n.index = k.index\n",
    "            \n",
    "            N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "            \n",
    "            assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "            assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "            \n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)\n",
    "            p_values.to_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\")\n",
    "            t2 = time.time()\n",
    "            print(f'{run}_{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCV-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-A'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra\n",
      "\n",
      "cityblock\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra', 'cityblock'}:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(distance)\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    \n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "    \n",
    "    runs = min(get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            if os.path.exists(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\"):\n",
    "                continue\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO2genes.index,\n",
    "                                                       columns = range(nb_clusters))\n",
    "\n",
    "            \n",
    "            k = nb_annotated_genes_in_cluster\n",
    "            \n",
    "            K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "            K.columns = k.columns\n",
    "            \n",
    "            n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "            n.index = k.index\n",
    "            \n",
    "            N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "            \n",
    "            assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "            assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "            \n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)\n",
    "            p_values.to_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\")\n",
    "            t2 = time.time()\n",
    "            print(f'{run}_{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-G'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra\n",
      "\n",
      "cityblock\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra', 'cityblock'}:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(distance)\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    \n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "    \n",
    "    runs = min(get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            if os.path.exists(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\"):\n",
    "                continue\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO2genes.index,\n",
    "                                                       columns = range(nb_clusters))\n",
    "\n",
    "            \n",
    "            k = nb_annotated_genes_in_cluster\n",
    "            \n",
    "            K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "            K.columns = k.columns\n",
    "            \n",
    "            n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "            n.index = k.index\n",
    "            \n",
    "            N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "            \n",
    "            assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "            assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "            \n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)\n",
    "            p_values.to_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\")\n",
    "            t2 = time.time()\n",
    "            print(f'{run}_{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCV-DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-DG'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra\n",
      "\n",
      "cityblock\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra', 'cityblock'}:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(distance)\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    \n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "    \n",
    "    runs = min(get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            if os.path.exists(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\"):\n",
    "                continue\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO2genes.index,\n",
    "                                                       columns = range(nb_clusters))\n",
    "\n",
    "            \n",
    "            k = nb_annotated_genes_in_cluster\n",
    "            \n",
    "            K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "            K.columns = k.columns\n",
    "            \n",
    "            n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "            n.index = k.index\n",
    "            \n",
    "            N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "            \n",
    "            if not (distance in {'correlation', 'mahalanobis'}):\n",
    "                assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "                assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "            \n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)\n",
    "            p_values.to_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\")\n",
    "            t2 = time.time()\n",
    "            print(f'{run}_{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCV-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-DA'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clusterduck123/Desktop/git/supplements/venv/graco/lib/python3.6/site-packages/pandas/core/computation/expressions.py:194: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  op=op_str, alt_op=unsupported[op_str]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26_99: 148.99sec\n",
      "cityblock\n",
      "26_99: 142.00sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra', 'cityblock'}:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(distance)\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    \n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "    \n",
    "    runs = min(get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            if os.path.exists(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\"):\n",
    "                continue\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO2genes.index,\n",
    "                                                       columns = range(nb_clusters))\n",
    "\n",
    "            \n",
    "            k = nb_annotated_genes_in_cluster\n",
    "            \n",
    "            K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "            K.columns = k.columns\n",
    "            \n",
    "            n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "            n.index = k.index\n",
    "            \n",
    "            N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "            \n",
    "            assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "            assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "            \n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)\n",
    "            p_values.to_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\")\n",
    "            t2 = time.time()\n",
    "            print(f'{run}_{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-all'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra\n",
      "\n",
      "cityblock\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra', 'cityblock'}:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(distance)\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    \n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "    \n",
    "    runs = min(get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            if os.path.exists(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\"):\n",
    "                continue\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO2genes.index,\n",
    "                                                       columns = range(nb_clusters))\n",
    "\n",
    "            \n",
    "            k = nb_annotated_genes_in_cluster\n",
    "            \n",
    "            K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "            K.columns = k.columns\n",
    "            \n",
    "            n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "            n.index = k.index\n",
    "            \n",
    "            N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "            \n",
    "            if not distance in {'correlation', 'mahalanobis'}:\n",
    "                assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "                assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "            \n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)\n",
    "            p_values.to_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\")\n",
    "            t2 = time.time()\n",
    "            print(f'{run}_{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-nonredundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-nonredundant'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra\n",
      "\n",
      "cityblock\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra', 'cityblock'}:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(distance)\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    \n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "    \n",
    "    runs = min(get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            if os.path.exists(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\"):\n",
    "                continue\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO2genes.index,\n",
    "                                                       columns = range(nb_clusters))\n",
    "\n",
    "            \n",
    "            k = nb_annotated_genes_in_cluster\n",
    "            \n",
    "            K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "            K.columns = k.columns\n",
    "            \n",
    "            n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "            n.index = k.index\n",
    "            \n",
    "            N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "            \n",
    "            if not distance in {'correlation', 'mahalanobis'}:\n",
    "                assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "                assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "            \n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)\n",
    "            p_values.to_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\")\n",
    "            t2 = time.time()\n",
    "            print(f'{run}_{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-orca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-orca'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellinger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'hellinger'}:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(distance)\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    \n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "    \n",
    "    runs = min(get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            if os.path.exists(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\"):\n",
    "                continue\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO2genes.index,\n",
    "                                                       columns = range(nb_clusters))\n",
    "\n",
    "            \n",
    "            k = nb_annotated_genes_in_cluster\n",
    "            \n",
    "            K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "            K.columns = k.columns\n",
    "            \n",
    "            n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "            n.index = k.index\n",
    "            \n",
    "            N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "            \n",
    "            if not distance in {'correlation', 'mahalanobis'}:\n",
    "                assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "                assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "            \n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)\n",
    "            p_values.to_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\")\n",
    "            t2 = time.time()\n",
    "            print(f'{run}_{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-orca+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-orca+'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra\n",
      "\n",
      "cityblock\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra', 'cityblock'}:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(distance)\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY  = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    \n",
    "    if not os.path.exists(PVALUE_DIRECTORY):\n",
    "        os.makedirs(PVALUE_DIRECTORY)\n",
    "    \n",
    "    runs = min(get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            if os.path.exists(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\"):\n",
    "                continue\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            nb_annotated_genes_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO2genes.index,\n",
    "                                                       columns = range(nb_clusters))\n",
    "\n",
    "            \n",
    "            k = nb_annotated_genes_in_cluster\n",
    "            \n",
    "            K = pd.concat([global_GO_counter[GO2genes.index]]*nb_clusters, axis=1)\n",
    "            K.columns = k.columns\n",
    "            \n",
    "            n = pd.concat([pd.DataFrame(map(len, cluster_list)).T]*len(GO2genes))\n",
    "            n.index = k.index\n",
    "            \n",
    "            N = pd.DataFrame(len(PPI), columns=k.columns, index=k.index)\n",
    "            \n",
    "            if not distance in {'correlation', 'mahalanobis'}:\n",
    "                assert K.eq(k.sum(axis=1), axis=0).all().all()\n",
    "                assert N.eq(n.sum(axis=1), axis=0).all().all()\n",
    "            \n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO2genes.index)\n",
    "            p_values.to_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\")\n",
    "            t2 = time.time()\n",
    "            print(f'{run}_{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graco",
   "language": "python",
   "name": "graco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
