{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice, combinations, product\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "from collections import defaultdict\n",
    "from scipy.stats import hypergeom\n",
    "from collections import Counter\n",
    "from goatools import obo_parser\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import time\n",
    "import graco\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "DATA_DIRECTORY = \"/home/clusterduck123/Desktop/git/supplements/data\"\n",
    "CPP_DIRECTORY = \"/home/clusterduck123/Desktop/git/graco/graco/cpp\"\n",
    "\n",
    "RAW_DATA_DIRECTORY = f\"{DATA_DIRECTORY}/raw_data\"\n",
    "PPI_DIRECTORY = f\"{DATA_DIRECTORY}/PPI\"\n",
    "ANNOTATIONS_DIRECTORY = f\"{DATA_DIRECTORY}/annotations\"\n",
    "MATRIX_DIRECTORY = f\"{DATA_DIRECTORY}/matrix\"\n",
    "CLUSTERS_DIRECTORY = f\"{DATA_DIRECTORY}/clusters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = 'CC'\n",
    "lb_GO = 5\n",
    "ub_GO = 500\n",
    "min_lvl = 0\n",
    "max_lvl = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and parse annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/clusterduck123/Desktop/git/supplements/data/raw_data/go-basic.obo: fmt(1.2) rel(2019-10-07) 47,285 GO Terms\n"
     ]
    }
   ],
   "source": [
    "PPI = nx.read_edgelist(f\"{PPI_DIRECTORY}/BioGRID_sc.txt\")\n",
    "\n",
    "annotation_df = pd.read_csv(f\"{ANNOTATIONS_DIRECTORY}/BioGRID-SGD_{namespace}_sc.csv\")\n",
    "\n",
    "go_dag = obo_parser.GODag(f\"{RAW_DATA_DIRECTORY}/go-basic.obo\")\n",
    "\n",
    "gene_population = set(PPI.nodes())\n",
    "GO_population = {go_id for go_id in set(annotation_df.GO_ID) \n",
    "                           if (lb_GO <= len(annotation_df[annotation_df.GO_ID == go_id]) <= ub_GO and\n",
    "                               min_lvl <= go_dag[go_id].level <= max_lvl)}\n",
    "\n",
    "annotation_df = annotation_df[annotation_df.GO_ID.isin(GO_population)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define convenient dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion dictionaries\n",
    "GO_index = pd.Series(iter(GO_population), name='GO-terms')\n",
    "GO2genes = pd.Series({go_id: set(genes.Systematic_ID) for go_id, genes in annotation_df.groupby('GO_ID')}, \n",
    "                     name='gene_sets')\n",
    "gene2GO  = {gene : set(go_ids.GO_ID)        for gene, go_ids in annotation_df.groupby('Systematic_ID')}\n",
    "global_GO_counter = GO2genes.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we GO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parser fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_max_runs(GV, distance, n_clusters):\n",
    "    runs = max(int(run) for run,species,db,ncluster_txt in \n",
    "             map(partial(str.split, sep='_'), os.listdir(f\"{CLUSTERS_DIRECTORY}/{GV}/{distance}\"))\n",
    "                if int(ncluster_txt.split('.')[0]) == n_clusters)\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_enriched_in_cluster(gene, cluster, enrichment):\n",
    "    return bool(gene2GOs[gene] & set(GO_index[enrichment[cluster]]))\n",
    "\n",
    "def cluster2GO(cluster):\n",
    "    return set.union(*(gene2GO.get(gene, set()) for gene in cluster))\n",
    "\n",
    "def is_annotated_in(gene, GO_set):\n",
    "    return not gene2GO.get(gene,set()).isdisjoint(GO_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enrichments(alpha, p_values, cluster_list):\n",
    "    relevant_p_values = [p_values[cluster_idx][cluster2GO(cluster)] \n",
    "                             for cluster_idx,cluster in enumerate(cluster_list)] \n",
    "    \n",
    "    sorted_p_values = sorted(p for p_cluster in relevant_p_values\n",
    "                               for p in p_cluster)\n",
    "    m = len(sorted_p_values)\n",
    "    c = np.log(m) + np.euler_gamma + 1/(2*m)\n",
    "    for k,P_k in enumerate(sorted_p_values,1):\n",
    "        if P_k > k/(m*c) * alpha:\n",
    "            break\n",
    "    threshold = sorted_p_values[k-2]\n",
    "    return p_values < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "MAX_RUNS = 10\n",
    "\n",
    "cluster_coverages = defaultdict(pd.DataFrame)\n",
    "GO_coverages      = defaultdict(pd.DataFrame)\n",
    "gene_coverages    = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gGCV-normalizedl1 0\n",
      "gGCV-normalizedl1 1\n",
      "gGCV-normalizedl1 2\n",
      "gGCV-normalizedl1 3\n",
      "gGCV-normalizedl1 4\n",
      "gGCV-normalizedl1 5\n",
      "gGCV-normalizedl1 6\n",
      "gGCV-normalizedl1 7\n",
      "gGCV-normalizedl1 8\n",
      "gGCV-normalizedl1 9\n",
      "99: 23.64sec\n",
      "gGCV-normalizedl2 0\n",
      "gGCV-normalizedl2 1\n",
      "gGCV-normalizedl2 2\n",
      "gGCV-normalizedl2 3\n",
      "gGCV-normalizedl2 4\n",
      "gGCV-normalizedl2 5\n",
      "gGCV-normalizedl2 6\n",
      "gGCV-normalizedl2 7\n",
      "gGCV-normalizedl2 8\n",
      "gGCV-normalizedl2 9\n",
      "99: 23.08sec\n",
      "gGCV-normalizedlinf 0\n",
      "gGCV-normalizedlinf 1\n",
      "gGCV-normalizedlinf 2\n",
      "gGCV-normalizedlinf 3\n",
      "gGCV-normalizedlinf 4\n",
      "gGCV-normalizedlinf 5\n",
      "gGCV-normalizedlinf 6\n",
      "72: 14.31sec\r"
     ]
    }
   ],
   "source": [
    "for method in ['gGCV_normalizedl1', 'gGCV_normalizedl2', 'gGCV_normalizedlinf', \n",
    "                'GDV_similarity', 'GCV_tvd', ]:\n",
    "    \n",
    "    if not os.path.exists(f\"{DATA_DIRECTORY}/enrichments/{namespace}/{method}\"):\n",
    "        os.makedirs(f\"{DATA_DIRECTORY}/enrichments/{namespace}/{method}\")\n",
    "    \n",
    "    GV, distance = method.split('_')\n",
    "    runs = min(get_number_of_max_runs(GV, distance, MAX_CLUSTERS-1), MAX_RUNS-1)\n",
    "\n",
    "    for run in range(runs+1):\n",
    "        \n",
    "        t1 = time.time()\n",
    "        print(f\"{GV}-{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages[method][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS))\n",
    "        GO_coverages[     method][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS))\n",
    "        gene_coverages[   method][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS))\n",
    "        \n",
    "        for n_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            \n",
    "\n",
    "            with open(f\"{CLUSTERS_DIRECTORY}/{GV}/{distance}/{run}_sc_BioGRID_{n_clusters}.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "\n",
    "            # For each GO term and cluster we get an experiment \n",
    "            enriched_GO_terms_in_cluster = pd.DataFrame(np.array(\n",
    "                    [ [len(go_genes & cluster) for cluster in cluster_list] for go_genes in GO2genes]),\n",
    "                                                       index   = GO_index,\n",
    "                                                       columns = range(n_clusters))\n",
    "\n",
    "            K = global_GO_counter.values.reshape(-1,1)\n",
    "            n = list(map(len, cluster_list))\n",
    "            k = enriched_GO_terms_in_cluster\n",
    "            N = sum(n)                               # PPI size, i.e. number of all genes that appear in a cluster\n",
    "\n",
    "            # scipy has a really messed up nomeclature... \n",
    "            p_values = pd.DataFrame(1-hypergeom.cdf(k=k-1, M=N, N=n, n=K), index=GO_population)\n",
    "            \n",
    "\n",
    "            enrichments = get_enrichments(alpha,p_values, cluster_list)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages[method][run][n_clusters] = sum(enrichments.any())      /n_clusters\n",
    "            GO_coverages[     method][run][n_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   method][run][n_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items())/N\n",
    "            t2 = time.time()\n",
    "            print(f'{n_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "        \n",
    "    cluster_coverages[method].to_csv(f\"{DATA_DIRECTORY}/enrichments/{namespace}/{method}/cluster_coverage.txt\")\n",
    "    GO_coverages[method].to_csv(f\"{DATA_DIRECTORY}/enrichments/{namespace}/{method}/GO_coverage.txt\")\n",
    "    gene_coverages[method].to_csv(f\"{DATA_DIRECTORY}/enrichments/{namespace}/{method}/gene_coverage.txt\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages[method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graco",
   "language": "python",
   "name": "graco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
