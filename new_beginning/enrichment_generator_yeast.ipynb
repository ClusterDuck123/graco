{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice, combinations, product\n",
    "from collections import defaultdict\n",
    "from goatools import obo_parser\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set()\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "DATA_DIRECTORY = \"/media/clusterduck123/joe/data\"\n",
    "RAW_DATA_DIRECTORY = f\"{DATA_DIRECTORY}/raw-data\"\n",
    "YEAST_DIRECTORY = f\"{DATA_DIRECTORY}/processed-data/yeast\"\n",
    "NETWORK_DIRECTORY = f\"{YEAST_DIRECTORY}/networks\"\n",
    "MATRIX_DIRECTORY  = f\"{YEAST_DIRECTORY}/distance-matrices\"\n",
    "ANNOTATION_DIRECTORY  = f\"{YEAST_DIRECTORY}/annotations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect = 'BP'\n",
    "correction = 'BH'\n",
    "\n",
    "alpha = 0.05\n",
    "lb_GO = 5\n",
    "ub_GO = 500\n",
    "min_lvl = 0\n",
    "max_lvl = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/clusterduck123/joe/data/raw-data/go-basic.obo: fmt(1.2) rel(2019-10-07) 47,285 GO Terms\n"
     ]
    }
   ],
   "source": [
    "PPI = nx.read_edgelist(f\"{NETWORK_DIRECTORY}/PPI_BioGRID.txt\")\n",
    "\n",
    "annotation_df = pd.read_csv(f\"{ANNOTATION_DIRECTORY}/GO_{aspect}_BioGRID-SGD.csv\")\n",
    "\n",
    "go_dag = obo_parser.GODag(f\"{RAW_DATA_DIRECTORY}/go-basic.obo\")\n",
    "\n",
    "gene_population = set(PPI.nodes())\n",
    "GO_population = {go_id for go_id in set(annotation_df.GO_ID) \n",
    "                           if (lb_GO <= len(annotation_df[annotation_df.GO_ID == go_id]) <= ub_GO and\n",
    "                               min_lvl <= go_dag[go_id].level <= max_lvl)}\n",
    "\n",
    "annotation_df = annotation_df[annotation_df.GO_ID.isin(GO_population)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion dictionaries\n",
    "GO2genes = pd.Series({go_id: set(genes.Systematic_ID) for go_id, genes in annotation_df.groupby('GO_ID')}, \n",
    "                     name='nb_genes')\n",
    "gene2GO = defaultdict(set)\n",
    "gene2GO  = {gene : set(go_ids.GO_ID)        for gene, go_ids in annotation_df.groupby('Systematic_ID')}\n",
    "global_GO_counter = GO2genes.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_pre_runs(PVALUE_DIRECTORY, n_clusters = 99):\n",
    "    splitted_file_names = [name.split('_') for name in os.listdir(PVALUE_DIRECTORY)]\n",
    "    pre_runs = [int(run) for run, ncluster, db_txt in splitted_file_names if ncluster == str(n_clusters)]\n",
    "    if pre_runs:\n",
    "        return max(pre_runs)+1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enrichments(alpha, p_values, cluster_list, correction):\n",
    "    relevant_p_values = [p_values[str(cluster_idx)][cluster2GO(cluster)] \n",
    "                             for cluster_idx,cluster in enumerate(cluster_list)] \n",
    "    \n",
    "    sorted_p_values = sorted(p for p_cluster in relevant_p_values\n",
    "                               for p in p_cluster)\n",
    "    m = len(sorted_p_values)\n",
    "    if   correction == 'BY':\n",
    "        c = np.log(m) + np.euler_gamma + 1/(2*m)\n",
    "    elif correction == 'BH':\n",
    "        c = 1\n",
    "    else:\n",
    "        print(\"Correction not known!\")\n",
    "        raise Exception\n",
    "    for k,P_k in enumerate(sorted_p_values,1):\n",
    "        if P_k > k/(m*c) * alpha:\n",
    "            break\n",
    "    threshold = sorted_p_values[k-2]\n",
    "    return p_values < threshold\n",
    "\n",
    "\n",
    "def cluster2GO(cluster):\n",
    "    return set.union(*(gene2GO.get(gene, set()) for gene in cluster))\n",
    "\n",
    "def is_annotated_in(gene, GO_set):\n",
    "    return not gene2GO.get(gene,set()).isdisjoint(GO_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages = {}\n",
    "GO_coverages      = {}\n",
    "gene_coverages    = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 99\n",
    "MAX_RUNS     = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GDV'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages['GDV'] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     'GDV'] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   'GDV'] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDV_similarity 0\n",
      "GDV_similarity 1\n",
      "GDV_similarity 2\n",
      "GDV_similarity 3\n",
      "GDV_similarity 4\n",
      "GDV_similarity 5\n",
      "GDV_similarity 6\n",
      "GDV_similarity 7\n",
      "GDV_similarity 8\n",
      "GDV_similarity 9\n",
      "98: 11.25sec\n",
      "braycurtis 0\n",
      "braycurtis 1\n",
      "braycurtis 2\n",
      "braycurtis 3\n",
      "braycurtis 4\n",
      "braycurtis 5\n",
      "braycurtis 6\n",
      "braycurtis 7\n",
      "braycurtis 8\n",
      "braycurtis 9\n",
      "98: 11.47sec\n",
      "canberra 0\n",
      "canberra 1ec\n",
      "canberra 2ec\n",
      "canberra 3ec\n",
      "canberra 4ec\n",
      "canberra 5ec\n",
      "canberra 6ec\n",
      "canberra 7ec\n",
      "canberra 8ec\n",
      "canberra 9ec\n",
      "98: 11.57sec\n",
      "chebyshev 0\n",
      "chebyshev 1c\n",
      "chebyshev 2c\n",
      "chebyshev 3c\n",
      "chebyshev 4c\n",
      "chebyshev 5c\n",
      "chebyshev 6c\n",
      "chebyshev 7c\n",
      "chebyshev 8c\n",
      "chebyshev 9c\n",
      "98: 16.06sec\n",
      "cityblock 0\n",
      "cityblock 1c\n",
      "cityblock 2c\n",
      "cityblock 3c\n",
      "cityblock 4c\n",
      "cityblock 5c\n",
      "cityblock 6c\n",
      "cityblock 7c\n",
      "cityblock 8c\n",
      "cityblock 9c\n",
      "98: 17.34sec\n",
      "correlation 0\n",
      "correlation 1\n",
      "correlation 2\n",
      "correlation 3\n",
      "correlation 4\n",
      "correlation 5\n",
      "correlation 6\n",
      "correlation 7\n",
      "correlation 8\n",
      "correlation 9\n",
      "98: 18.78sec\n",
      "cosine 0\n",
      "cosine 17sec\n",
      "cosine 22sec\n",
      "cosine 36sec\n",
      "cosine 49sec\n",
      "cosine 58sec\n",
      "cosine 60sec\n",
      "cosine 71sec\n",
      "cosine 84sec\n",
      "cosine 95sec\n",
      "98: 15.65sec\n",
      "euclidean 0\n",
      "euclidean 1c\n",
      "euclidean 2c\n",
      "euclidean 3c\n",
      "euclidean 4c\n",
      "euclidean 5c\n",
      "euclidean 6c\n",
      "euclidean 7c\n",
      "euclidean 8c\n",
      "euclidean 9c\n",
      "98: 13.99sec\n",
      "mahalanobis 0\n",
      "mahalanobis 1\n",
      "mahalanobis 2\n",
      "mahalanobis 3\n",
      "mahalanobis 4\n",
      "mahalanobis 5\n",
      "mahalanobis 6\n",
      "mahalanobis 7\n",
      "mahalanobis 8\n",
      "mahalanobis 9\n",
      "98: 12.16sec\n",
      "normalized1_l1 0\n",
      "normalized1_l1 1\n",
      "normalized1_l1 2\n",
      "normalized1_l1 3\n",
      "normalized1_l1 4\n",
      "normalized1_l1 5\n",
      "normalized1_l1 6\n",
      "normalized1_l1 7\n",
      "normalized1_l1 8\n",
      "normalized1_l1 9\n",
      "98: 12.88sec\n",
      "normalized1_l2 0\n",
      "normalized1_l2 1\n",
      "normalized1_l2 2\n",
      "normalized1_l2 3\n",
      "normalized1_l2 4\n",
      "normalized1_l2 5\n",
      "normalized1_l2 6\n",
      "normalized1_l2 7\n",
      "normalized1_l2 8\n",
      "normalized1_l2 9\n",
      "98: 17.67sec\n",
      "normalized1_linf 0\n",
      "normalized1_linf 1\n",
      "normalized1_linf 2\n",
      "normalized1_linf 3\n",
      "normalized1_linf 4\n",
      "normalized1_linf 5\n",
      "normalized1_linf 6\n",
      "normalized1_linf 7\n",
      "normalized1_linf 8\n",
      "normalized1_linf 9\n",
      "98: 12.35sec\n",
      "normalized2_l1 0\n",
      "normalized2_l1 1\n",
      "normalized2_l1 2\n",
      "normalized2_l1 3\n",
      "normalized2_l1 4\n",
      "normalized2_l1 5\n",
      "normalized2_l1 6\n",
      "normalized2_l1 7\n",
      "normalized2_l1 8\n",
      "normalized2_l1 9\n",
      "98: 14.76sec\n",
      "normalized2_l2 0\n",
      "normalized2_l2 1\n",
      "normalized2_l2 2\n",
      "normalized2_l2 3\n",
      "normalized2_l2 4\n",
      "normalized2_l2 5\n",
      "normalized2_l2 6\n",
      "normalized2_l2 7\n",
      "normalized2_l2 8\n",
      "normalized2_l2 9\n",
      "98: 14.07sec\n",
      "normalized2_linf 0\n",
      "normalized2_linf 1\n",
      "normalized2_linf 2\n",
      "normalized2_linf 3\n",
      "normalized2_linf 4\n",
      "normalized2_linf 5\n",
      "normalized2_linf 6\n",
      "normalized2_linf 7\n",
      "normalized2_linf 8\n",
      "normalized2_linf 9\n",
      "98: 13.41sec\n",
      "seuclidean 0\n",
      "seuclidean 1\n",
      "seuclidean 2\n",
      "seuclidean 3\n",
      "seuclidean 4\n",
      "seuclidean 5\n",
      "seuclidean 6\n",
      "seuclidean 7\n",
      "seuclidean 8\n",
      "seuclidean 9\n",
      "98: 13.04sec\n",
      "sqeuclidean 0\n",
      "sqeuclidean 1\n",
      "sqeuclidean 2\n",
      "sqeuclidean 3\n",
      "sqeuclidean 4\n",
      "sqeuclidean 5\n",
      "sqeuclidean 6\n",
      "sqeuclidean 7\n",
      "sqeuclidean 8\n",
      "sqeuclidean 9\n",
      "98: 12.48sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in all_distances:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GDV/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/GDV/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages['GDV'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS)) \n",
    "        GO_coverages[     'GDV'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS))\n",
    "        gene_coverages[   'GDV'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages['GDV'][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     'GDV'][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   'GDV'][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/GDV/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages['GDV'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     'GDV'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   'GDV'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages['GCV-A'] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     'GCV-A'] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   'GCV-A'] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra 0\n",
      "canberra 1ec\n",
      "canberra 2ec\n",
      "canberra 3ec\n",
      "canberra 4ec\n",
      "canberra 5ec\n",
      "canberra 6ec\n",
      "canberra 7ec\n",
      "canberra 8ec\n",
      "canberra 9ec\n",
      "canberra 10c\n",
      "canberra 11c\n",
      "canberra 12c\n",
      "canberra 13c\n",
      "canberra 14c\n",
      "canberra 15c\n",
      "canberra 16c\n",
      "canberra 17c\n",
      "canberra 18c\n",
      "canberra 19c\n",
      "canberra 20c\n",
      "canberra 21c\n",
      "canberra 22c\n",
      "canberra 23c\n",
      "canberra 24c\n",
      "canberra 25c\n",
      "canberra 26c\n",
      "canberra 27c\n",
      "canberra 28c\n",
      "canberra 29c\n",
      "98: 11.34sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in ['canberra']:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GCV-A/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/GCV-A/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages['GCV-A'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     'GCV-A'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   'GCV-A'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages['GCV-A'][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     'GCV-A'][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   'GCV-A'][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/GCV-A/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages['GCV-A'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     'GCV-A'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   'GCV-A'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCV-G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages['GCV-G'] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     'GCV-G'] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   'GCV-G'] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra 0\n",
      "canberra 1ec\n",
      "canberra 2ec\n",
      "canberra 3ec\n",
      "canberra 4ec\n",
      "canberra 5ec\n",
      "canberra 6ec\n",
      "canberra 7ec\n",
      "canberra 8ec\n",
      "canberra 9ec\n",
      "canberra 10c\n",
      "canberra 11c\n",
      "canberra 12c\n",
      "canberra 13c\n",
      "canberra 14c\n",
      "canberra 15c\n",
      "canberra 16c\n",
      "canberra 17c\n",
      "canberra 18c\n",
      "canberra 19c\n",
      "canberra 20c\n",
      "canberra 21c\n",
      "canberra 22c\n",
      "canberra 23c\n",
      "canberra 24c\n",
      "canberra 25c\n",
      "canberra 26c\n",
      "canberra 27c\n",
      "canberra 28c\n",
      "canberra 29c\n",
      "98: 11.29sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in ['canberra']:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GCV-G/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/GCV-G/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages['GCV-G'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     'GCV-G'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   'GCV-G'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages['GCV-G'][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     'GCV-G'][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   'GCV-G'][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/GCV-G/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages['GCV-G'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     'GCV-G'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   'GCV-G'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCV-DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-DG'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages[feature] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     feature] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   feature] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra 0\n",
      "canberra 1ec\n",
      "canberra 2ec\n",
      "canberra 3ec\n",
      "canberra 4ec\n",
      "canberra 5ec\n",
      "canberra 6ec\n",
      "canberra 7ec\n",
      "canberra 8ec\n",
      "canberra 9ec\n",
      "98: 11.56sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra'}:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages[feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages[feature][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     feature][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   feature][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/{feature}/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages[feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCV-AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages['GCV-AD'] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     'GCV-AD'] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   'GCV-AD'] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra 0\n",
      "canberra 1ec\n",
      "canberra 2ec\n",
      "canberra 3ec\n",
      "canberra 4ec\n",
      "canberra 5ec\n",
      "canberra 6ec\n",
      "canberra 7ec\n",
      "canberra 8ec\n",
      "canberra 9ec\n",
      "98: 15.54sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in ['canberra']:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GCV-AD/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/GCV-AD/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages['GCV-AD'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     'GCV-AD'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   'GCV-AD'][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages['GCV-AD'][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     'GCV-AD'][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   'GCV-AD'][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/GCV-AD/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages['GCV-AD'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     'GCV-AD'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   'GCV-AD'][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-all'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages[feature] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     feature] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   feature] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra 0\n",
      "canberra 1ec\n",
      "canberra 2ec\n",
      "canberra 3ec\n",
      "canberra 4ec\n",
      "98: 11.62sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra'}:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages[feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages[feature][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     feature][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   feature][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/{feature}/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages[feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-nonredundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-nonredundant'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages[feature] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     feature] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   feature] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canberra 0\n",
      "canberra 1ec\n",
      "canberra 2ec\n",
      "canberra 3ec\n",
      "canberra 4ec\n",
      "98: 15.77sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'canberra'}:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages[feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages[feature][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     feature][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   feature][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/{feature}/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages[feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-orca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-orca'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages[feature] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     feature] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   feature] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellinger 0\n",
      "hellinger 1c\n",
      "hellinger 2c\n",
      "hellinger 3c\n",
      "hellinger 4c\n",
      "hellinger 5c\n",
      "hellinger 6c\n",
      "hellinger 7c\n",
      "hellinger 8c\n",
      "hellinger 9c\n",
      "98: 10.39sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'hellinger'}:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages[feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages[feature][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     feature][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   feature][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/{feature}/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages[feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-orca+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'GCV-orca+'\n",
    "\n",
    "all_distances = sorted('_'.join(filename.split('_')[:-1]) \n",
    "                           for filename in os.listdir(f\"{MATRIX_DIRECTORY}/{feature}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coverages[feature] = defaultdict(pd.DataFrame)\n",
    "GO_coverages[     feature] = defaultdict(pd.DataFrame)\n",
    "gene_coverages[   feature] = defaultdict(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cityblock 0\n",
      "cityblock 1c\n",
      "cityblock 2c\n",
      "cityblock 3c\n",
      "cityblock 4c\n",
      "cityblock 5c\n",
      "cityblock 6c\n",
      "cityblock 7c\n",
      "cityblock 8c\n",
      "cityblock 9c\n",
      "98: 10.41sec\n"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for distance in {'cityblock'}:\n",
    "    \n",
    "    CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/{feature}/{distance}/{method}\"\n",
    "    PVALUE_DIRECTORY = f\"{YEAST_DIRECTORY}/p-values/{feature}/{distance}/{method}/{aspect}\"\n",
    "    runs = min(get_number_of_pre_runs(PVALUE_DIRECTORY, MAX_CLUSTERS), MAX_RUNS)\n",
    "\n",
    "    for run in range(runs):\n",
    "        t1 = time.time()\n",
    "        print(f\"{distance} {run}\")\n",
    "        \n",
    "        cluster_coverages[feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2)) \n",
    "        GO_coverages[     feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        gene_coverages[   feature][distance][run] = pd.Series(np.nan, index=range(MIN_CLUSTERS, MAX_CLUSTERS+2))\n",
    "        \n",
    "        for nb_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS):\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "            cluster_df = pd.Series({gene:cluster_idx \n",
    "                                        for cluster_idx,cluster in enumerate(cluster_list) \n",
    "                                        for gene in cluster})\n",
    "            \n",
    "            p_values = pd.read_csv(f\"{PVALUE_DIRECTORY}/{run}_{nb_clusters}_BioGRID.txt\", index_col=0)\n",
    "\n",
    "            enrichments = get_enrichments(alpha, p_values, cluster_list, correction)\n",
    "            enrichmet_list = [set(enrichments[i][enrichments[i]].index) for i in enrichments.columns]\n",
    "            \n",
    "            cluster_coverages[feature][distance][run][nb_clusters] = sum(enrichments.any())      / nb_clusters\n",
    "            GO_coverages[     feature][distance][run][nb_clusters] = sum(enrichments.any(axis=1))/len(GO_population)\n",
    "            gene_coverages[   feature][distance][run][nb_clusters] = sum(is_annotated_in(gene,enrichmet_list[cluster_idx])\n",
    "                                                             for gene, cluster_idx in cluster_df.items()) / len(PPI)\n",
    "            t2 = time.time()\n",
    "            print(f'{nb_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "            \n",
    "    ENRICHMENT_DIRECTORY = f\"{YEAST_DIRECTORY}/enrichments/{feature}/{distance}/{method}/{aspect}/{correction}\"\n",
    "    if not os.path.exists(ENRICHMENT_DIRECTORY):\n",
    "        os.makedirs(ENRICHMENT_DIRECTORY)\n",
    "        \n",
    "    cluster_coverages[feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/clusters.csv\")\n",
    "    GO_coverages[     feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/GO-terms.csv\")\n",
    "    gene_coverages[   feature][distance].to_csv(f\"{ENRICHMENT_DIRECTORY}/genes.csv\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graco",
   "language": "python",
   "name": "graco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
