{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "from functools import partial\n",
    "from random import sample\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"/home/clusterduck123/Desktop/git/supplements/data\"\n",
    "HUMAN_DIRECTORY = f\"{DATA_DIRECTORY}/processed-data/organisms/human\"\n",
    "NETWORK_DIRECTORY = f\"{HUMAN_DIRECTORY}/networks\"\n",
    "MATRIX_DIRECTORY  = f\"{HUMAN_DIRECTORY}/distance-matrices\"\n",
    "ANNOTATION_DIRECTORY = f\"{HUMAN_DIRECTORY}/annotations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_pre_runs(GV, distance, n_clusters = 99):\n",
    "    splitted_file_names = [name.split('_') for name in os.listdir(f\"{CLUSTER_DIRECTORY}\")]\n",
    "    pre_runs = [int(run) for run, ncluster, db_txt in splitted_file_names if ncluster == str(n_clusters)]\n",
    "    if pre_runs:\n",
    "        return max(pre_runs)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "\n",
    "all_distances = [filename.split('_')[0] for filename in os.listdir(f\"{MATRIX_DIRECTORY}/GDV\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mahalanobis\n",
      "100: 5305.09sec\n",
      "GDV-similarity\n",
      "62: 3261.87sec\r"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bc503be2b133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{CLUSTER_DIRECTORY}/{nr+1}_{n_clusters}_BioGRID.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkmedoids_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{n_clusters}: {t2-t1:.2f}sec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for run in range(40):\n",
    "    for distance in ['mahalanobis', 'GDV-similarity', 'normalized1-l2', 'normalized1-l1', 'normalized1-linf']:\n",
    "        print(distance)\n",
    "        \n",
    "        CLUSTER_DIRECTORY = f\"{HUMAN_DIRECTORY}/clusterings/GDV/{distance}/{method}\"\n",
    "        if not os.path.exists(CLUSTER_DIRECTORY):\n",
    "            os.makedirs(CLUSTER_DIRECTORY)\n",
    "            \n",
    "        df = pd.read_csv(f\"{MATRIX_DIRECTORY}/GDV/{distance}_BioGRID.txt\", delimiter=' ')\n",
    "        D  = df.values.astype(float) \n",
    "\n",
    "        t1 = time.time()\n",
    "        for n_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS+1):\n",
    "            initial_medoids = sample(range(len(D)), n_clusters)\n",
    "            kmedoids_instance = kmedoids(D, initial_medoids, data_type='distance_matrix')\n",
    "            kmedoids_instance.process()\n",
    "            \n",
    "            nr = get_number_of_pre_runs('GDV', distance, MAX_CLUSTERS)\n",
    "\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{nr+1}_{n_clusters}_BioGRID.txt\", 'w') as f:\n",
    "                for cluster in kmedoids_instance.get_clusters():\n",
    "                    f.write(' '.join(df.columns[cluster]) + '\\n')\n",
    "            t2 = time.time()\n",
    "            print(f'{n_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "\n",
    "all_distances = ['canberra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated\n",
    "for run in range(50):\n",
    "    for distance in all_distances:\n",
    "        print(distance)\n",
    "\n",
    "        if not os.path.exists(f\"{CLUSTERS_DIRECTORY}/GCV/{distance}\"):\n",
    "            os.makedirs(f\"{CLUSTERS_DIRECTORY}/GCV/{distance}\")\n",
    "\n",
    "        MATRIX_NAME = f\"sc_BioGRID_GCV_{distance}\"\n",
    "        with open(f\"{MATRIX_DIRECTORY}/{MATRIX_NAME}.txt\", 'r') as f:\n",
    "            line = f.readline()\n",
    "        D = np.genfromtxt(f\"{MATRIX_DIRECTORY}/{MATRIX_NAME}.txt\", skip_header=1)\n",
    "\n",
    "        int2gene = dict(enumerate(line.split()))\n",
    "        \n",
    "        t1 = time.time()\n",
    "        for n_clusters in range(2, 100):\n",
    "            nr = get_number_of_max_runs('GCV', distance, n_clusters)\n",
    "        \n",
    "            initial_medoids = sample(range(len(D)), n_clusters)\n",
    "            kmedoids_instance = kmedoids(D, initial_medoids, data_type='distance_matrix')\n",
    "            kmedoids_instance.process()\n",
    "\n",
    "            with open(f\"{CLUSTERS_DIRECTORY}/GCV/{distance}/{nr+1}_sc_BioGRID_{n_clusters}.txt\", 'w') as f:\n",
    "                for cluster in kmedoids_instance.get_clusters():\n",
    "                    f.write(' '.join(map(int2gene.get,cluster)) + '\\n')\n",
    "            t2 = time.time()\n",
    "            print(f'{n_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gGCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "\n",
    "all_distances = ['normalizedlinf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizedlinf\n",
      "99: 569.67sec\n",
      "normalizedlinf\n",
      "99: 555.84sec\n",
      "normalizedlinf\n",
      "99: 554.14sec\n",
      "normalizedlinf\n",
      "99: 555.52sec\n",
      "normalizedlinf\n",
      "99: 554.21sec\n",
      "normalizedlinf\n",
      "99: 555.25sec\n",
      "normalizedlinf\n",
      "99: 554.59sec\n",
      "normalizedlinf\n",
      "99: 554.19sec\n",
      "normalizedlinf\n",
      "99: 554.66sec\n",
      "normalizedlinf\n",
      "99: 555.05sec\n",
      "normalizedlinf\n",
      "99: 554.81sec\n",
      "normalizedlinf\n",
      "99: 554.58sec\n",
      "normalizedlinf\n",
      "99: 554.33sec\n",
      "normalizedlinf\n",
      "99: 554.85sec\n",
      "normalizedlinf\n",
      "99: 555.31sec\n",
      "normalizedlinf\n",
      "99: 554.66sec\n",
      "normalizedlinf\n",
      "99: 554.98sec\n",
      "normalizedlinf\n",
      "99: 554.77sec\n",
      "normalizedlinf\n",
      "99: 555.27sec\n",
      "normalizedlinf\n",
      "99: 555.33sec\n",
      "normalizedlinf\n",
      "99: 554.48sec\n",
      "normalizedlinf\n",
      "99: 555.08sec\n",
      "normalizedlinf\n",
      "99: 555.41sec\n",
      "normalizedlinf\n",
      "99: 554.54sec\n",
      "normalizedlinf\n",
      "99: 554.56sec\n",
      "normalizedlinf\n",
      "99: 556.31sec\n",
      "normalizedlinf\n",
      "99: 554.94sec\n",
      "normalizedlinf\n",
      "99: 555.55sec\n",
      "normalizedlinf\n",
      "99: 554.78sec\n",
      "normalizedlinf\n",
      "99: 555.50sec\n",
      "normalizedlinf\n",
      "99: 555.09sec\n",
      "normalizedlinf\n",
      "99: 554.69sec\n",
      "normalizedlinf\n",
      "99: 554.88sec\n",
      "normalizedlinf\n",
      "99: 555.27sec\n",
      "normalizedlinf\n",
      "99: 555.07sec\n",
      "normalizedlinf\n",
      "99: 555.76sec\n",
      "normalizedlinf\n",
      "99: 540.33sec\n",
      "normalizedlinf\n",
      "99: 529.24sec\n",
      "normalizedlinf\n",
      "99: 524.44sec\n",
      "normalizedlinf\n",
      "99: 523.82sec\n",
      "normalizedlinf\n",
      "99: 524.23sec\n",
      "normalizedlinf\n",
      "99: 523.94sec\n",
      "normalizedlinf\n",
      "99: 525.23sec\n",
      "normalizedlinf\n",
      "99: 524.44sec\n",
      "normalizedlinf\n",
      "99: 524.37sec\n",
      "normalizedlinf\n",
      "99: 524.98sec\n",
      "normalizedlinf\n",
      "99: 524.53sec\n",
      "normalizedlinf\n",
      "99: 524.52sec\n",
      "normalizedlinf\n",
      "99: 524.31sec\n"
     ]
    }
   ],
   "source": [
    "# Automated\n",
    "for run in range(49):\n",
    "    for distance in all_distances:\n",
    "        print(distance)\n",
    "\n",
    "        if not os.path.exists(f\"{CLUSTERS_DIRECTORY}/gGCV/{distance}\"):\n",
    "            os.makedirs(f\"{CLUSTERS_DIRECTORY}/gGCV/{distance}\")\n",
    "\n",
    "        MATRIX_NAME = f\"sc_BioGRID_gGCV_{distance}\"\n",
    "        with open(f\"{MATRIX_DIRECTORY}/{MATRIX_NAME}.txt\", 'r') as f:\n",
    "            line = f.readline()\n",
    "        D = np.loadtxt(f\"{MATRIX_DIRECTORY}/{MATRIX_NAME}.txt\", skiprows=1)\n",
    "\n",
    "        int2gene = dict(enumerate(line.split()))\n",
    "        \n",
    "        t1 = time.time()\n",
    "        for n_clusters in range(2, 100):\n",
    "            nr = get_number_of_max_runs('gGCV', distance, MAX_CLUSTERS-1) # CAREFULL !!!!!\n",
    "            initial_medoids = sample(range(len(D)), n_clusters)\n",
    "            kmedoids_instance = kmedoids(D, initial_medoids, data_type='distance_matrix')\n",
    "            kmedoids_instance.process()\n",
    "\n",
    "            with open(f\"{CLUSTERS_DIRECTORY}/gGCV/{distance}/{nr+1}_sc_BioGRID_{n_clusters}.txt\", 'w') as f:\n",
    "                for cluster in kmedoids_instance.get_clusters():\n",
    "                    f.write(' '.join(map(int2gene.get,cluster)) + '\\n')\n",
    "            t2 = time.time()\n",
    "            print(f'{n_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graco",
   "language": "python",
   "name": "graco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
