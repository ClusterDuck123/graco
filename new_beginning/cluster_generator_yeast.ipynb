{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "from functools import partial\n",
    "from random import sample\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"/home/clusterduck123/Desktop/git/supplements/data\"\n",
    "YEAST_DIRECTORY = f\"{DATA_DIRECTORY}/processed-data/organisms/yeast\"\n",
    "NETWORK_DIRECTORY = f\"{YEAST_DIRECTORY}/networks\"\n",
    "MATRIX_DIRECTORY  = f\"{YEAST_DIRECTORY}/distance-matrices\"\n",
    "ANNOTATION_DIRECTORY = f\"{YEAST_DIRECTORY}/annotations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, n_clusters = 99):\n",
    "    splitted_file_names = [name.split('_') for name in os.listdir(CLUSTER_DIRECTORY)]\n",
    "    pre_runs = [int(run) for run, ncluster, db_txt in splitted_file_names if ncluster == str(n_clusters)]\n",
    "    if pre_runs:\n",
    "        return max(pre_runs)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "\n",
    "all_distances = [filename.split('_')[0] for filename in os.listdir(f\"{MATRIX_DIRECTORY}/GDV\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mahalanobis\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4ed50ce35ed8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLUSTER_DIRECTORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{MATRIX_DIRECTORY}/GDV/{distance}_BioGRID.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mD\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/git/supplements/venv/graco/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/git/supplements/venv/graco/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/git/supplements/venv/graco/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/git/supplements/venv/graco/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/git/supplements/venv/graco/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m     \"\"\"\n\u001b[1;32m    680\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for run in range(49):\n",
    "    for distance in all_distances:\n",
    "        print(distance)\n",
    "        \n",
    "        CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GDV/{distance}/{method}\"\n",
    "        if not os.path.exists(CLUSTER_DIRECTORY):\n",
    "            os.makedirs(CLUSTER_DIRECTORY)\n",
    "            \n",
    "        df = pd.read_csv(f\"{MATRIX_DIRECTORY}/GDV/{distance}_BioGRID.txt\", delimiter=' ')\n",
    "        D  = df.values.astype(float) \n",
    "\n",
    "        t1 = time.time()\n",
    "        for n_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS+1):\n",
    "            initial_medoids = sample(range(len(D)), n_clusters)\n",
    "            kmedoids_instance = kmedoids(D, initial_medoids, data_type='distance_matrix')\n",
    "            kmedoids_instance.process()\n",
    "            \n",
    "            nr = get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS)\n",
    "\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{nr+1}_{n_clusters}_BioGRID.txt\", 'w') as f:\n",
    "                for cluster in kmedoids_instance.get_clusters():\n",
    "                    f.write(' '.join(df.columns[cluster]) + '\\n')\n",
    "            t2 = time.time()\n",
    "            print(f'{n_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "\n",
    "all_distances = [filename.split('_')[0] for filename in os.listdir(f\"{MATRIX_DIRECTORY}/GCV-A\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for run in range(40):\n",
    "    for distance in ['all1_normalized1-linf',\n",
    "                     'all1_normalized1-l2', 'all2_normalized1-l2',\n",
    "                     'all1_normalized1-l1', 'all2_normalized1-l1']:\n",
    "        print(distance)\n",
    "        \n",
    "        CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GCV-A/{distance}/{method}\"\n",
    "        if not os.path.exists(CLUSTER_DIRECTORY):\n",
    "            os.makedirs(CLUSTER_DIRECTORY)\n",
    "            \n",
    "        df = pd.read_csv(f\"{MATRIX_DIRECTORY}/GCV-A/{distance}_BioGRID.txt\", delimiter=' ')\n",
    "        D  = df.values.astype(float) \n",
    "\n",
    "        t1 = time.time()\n",
    "        for n_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS+1):\n",
    "            initial_medoids = sample(range(len(D)), n_clusters)\n",
    "            kmedoids_instance = kmedoids(D, initial_medoids, data_type='distance_matrix')\n",
    "            kmedoids_instance.process()\n",
    "            \n",
    "            nr = get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS)\n",
    "\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{nr+1}_{n_clusters}_BioGRID.txt\", 'w') as f:\n",
    "                for cluster in kmedoids_instance.get_clusters():\n",
    "                    f.write(' '.join(df.columns[cluster]) + '\\n')\n",
    "            t2 = time.time()\n",
    "            print(f'{n_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCV-G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "\n",
    "all_distances = [filename.split('_')[0] for filename in os.listdir(f\"{MATRIX_DIRECTORY}/GCV-G\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all1_normalized1-linf\n",
      "100: 602.35sec\n",
      "all1_normalized1-l2\n",
      "100: 580.59sec\n",
      "all2_normalized1-l2\n",
      "100: 575.04sec\n",
      "all1_normalized1-l1\n",
      "100: 568.49sec\n",
      "all2_normalized1-l1\n",
      "100: 564.82sec\n",
      "all1_normalized1-linf\n",
      "100: 565.43sec\n",
      "all1_normalized1-l2\n",
      "100: 577.16sec\n",
      "all2_normalized1-l2\n",
      "100: 567.29sec\n",
      "all1_normalized1-l1\n",
      "100: 572.05sec\n",
      "all2_normalized1-l1\n",
      "100: 570.58sec\n",
      "all1_normalized1-linf\n",
      "100: 559.27sec\n",
      "all1_normalized1-l2\n",
      "100: 600.90sec\n",
      "all2_normalized1-l2\n",
      "100: 567.37sec\n",
      "all1_normalized1-l1\n",
      "100: 560.18sec\n",
      "all2_normalized1-l1\n",
      "100: 579.34sec\n",
      "all1_normalized1-linf\n",
      "100: 575.23sec\n",
      "all1_normalized1-l2\n",
      "100: 563.00sec\n",
      "all2_normalized1-l2\n",
      "100: 581.14sec\n",
      "all1_normalized1-l1\n",
      "100: 575.97sec\n",
      "all2_normalized1-l1\n",
      "100: 562.78sec\n",
      "all1_normalized1-linf\n",
      "100: 575.99sec\n",
      "all1_normalized1-l2\n",
      "100: 559.14sec\n",
      "all2_normalized1-l2\n",
      "100: 564.16sec\n",
      "all1_normalized1-l1\n",
      "100: 561.74sec\n",
      "all2_normalized1-l1\n",
      "100: 574.72sec\n",
      "all1_normalized1-linf\n",
      "100: 568.96sec\n",
      "all1_normalized1-l2\n",
      "100: 577.88sec\n",
      "all2_normalized1-l2\n",
      "100: 573.14sec\n",
      "all1_normalized1-l1\n",
      "100: 562.56sec\n",
      "all2_normalized1-l1\n",
      "100: 577.70sec\n",
      "all1_normalized1-linf\n",
      "100: 572.30sec\n",
      "all1_normalized1-l2\n",
      "100: 560.21sec\n",
      "all2_normalized1-l2\n",
      "100: 572.30sec\n",
      "all1_normalized1-l1\n",
      "100: 570.58sec\n",
      "all2_normalized1-l1\n",
      "100: 568.96sec\n",
      "all1_normalized1-linf\n",
      "100: 582.51sec\n",
      "all1_normalized1-l2\n",
      "100: 579.09sec\n",
      "all2_normalized1-l2\n",
      "100: 565.74sec\n",
      "all1_normalized1-l1\n",
      "100: 583.78sec\n",
      "all2_normalized1-l1\n",
      "100: 571.37sec\n",
      "all1_normalized1-linf\n",
      "100: 563.67sec\n",
      "all1_normalized1-l2\n",
      "100: 580.76sec\n",
      "all2_normalized1-l2\n",
      "100: 567.09sec\n",
      "all1_normalized1-l1\n",
      "100: 565.98sec\n",
      "all2_normalized1-l1\n",
      "100: 572.29sec\n",
      "all1_normalized1-linf\n",
      "100: 572.22sec\n",
      "all1_normalized1-l2\n",
      "100: 563.08sec\n",
      "all2_normalized1-l2\n",
      "100: 575.52sec\n",
      "all1_normalized1-l1\n",
      "100: 562.74sec\n",
      "all2_normalized1-l1\n",
      "100: 565.45sec\n",
      "all1_normalized1-linf\n",
      "100: 570.91sec\n",
      "all1_normalized1-l2\n",
      "100: 571.74sec\n",
      "all2_normalized1-l2\n",
      "100: 563.90sec\n",
      "all1_normalized1-l1\n",
      "100: 576.52sec\n",
      "all2_normalized1-l1\n",
      "100: 577.67sec\n",
      "all1_normalized1-linf\n",
      "100: 561.65sec\n",
      "all1_normalized1-l2\n",
      "100: 571.52sec\n",
      "all2_normalized1-l2\n",
      "100: 572.11sec\n",
      "all1_normalized1-l1\n",
      "100: 576.73sec\n",
      "all2_normalized1-l1\n",
      "100: 571.63sec\n",
      "all1_normalized1-linf\n",
      "100: 566.92sec\n",
      "all1_normalized1-l2\n",
      "100: 558.34sec\n",
      "all2_normalized1-l2\n",
      "100: 580.63sec\n",
      "all1_normalized1-l1\n",
      "100: 567.83sec\n",
      "all2_normalized1-l1\n",
      "100: 560.36sec\n",
      "all1_normalized1-linf\n",
      "100: 572.11sec\n",
      "all1_normalized1-l2\n",
      "100: 569.40sec\n",
      "all2_normalized1-l2\n",
      "100: 560.68sec\n",
      "all1_normalized1-l1\n",
      "100: 570.65sec\n",
      "all2_normalized1-l1\n",
      "100: 574.31sec\n",
      "all1_normalized1-linf\n",
      "100: 563.77sec\n",
      "all1_normalized1-l2\n",
      "100: 582.93sec\n",
      "all2_normalized1-l2\n",
      "100: 577.67sec\n",
      "all1_normalized1-l1\n",
      "100: 563.60sec\n",
      "all2_normalized1-l1\n",
      "100: 584.52sec\n",
      "all1_normalized1-linf\n",
      "100: 571.59sec\n",
      "all1_normalized1-l2\n",
      "100: 560.66sec\n",
      "all2_normalized1-l2\n",
      "100: 587.09sec\n",
      "all1_normalized1-l1\n",
      "100: 597.44sec\n",
      "all2_normalized1-l1\n",
      "100: 596.07sec\n",
      "all1_normalized1-linf\n",
      "100: 609.58sec\n",
      "all1_normalized1-l2\n",
      "100: 596.86sec\n",
      "all2_normalized1-l2\n",
      "100: 596.68sec\n",
      "all1_normalized1-l1\n",
      "100: 598.81sec\n",
      "all2_normalized1-l1\n",
      "100: 593.49sec\n",
      "all1_normalized1-linf\n",
      "100: 600.93sec\n",
      "all1_normalized1-l2\n",
      "100: 604.51sec\n",
      "all2_normalized1-l2\n",
      "100: 599.08sec\n",
      "all1_normalized1-l1\n",
      "100: 597.51sec\n",
      "all2_normalized1-l1\n",
      "100: 607.47sec\n",
      "all1_normalized1-linf\n",
      "100: 597.91sec\n",
      "all1_normalized1-l2\n",
      "100: 595.44sec\n",
      "all2_normalized1-l2\n",
      "100: 614.23sec\n",
      "all1_normalized1-l1\n",
      "100: 594.63sec\n",
      "all2_normalized1-l1\n",
      "100: 595.05sec\n",
      "all1_normalized1-linf\n",
      "100: 587.19sec\n",
      "all1_normalized1-l2\n",
      "100: 567.95sec\n",
      "all2_normalized1-l2\n",
      "100: 558.81sec\n",
      "all1_normalized1-l1\n",
      "100: 570.96sec\n",
      "all2_normalized1-l1\n",
      "100: 577.21sec\n",
      "all1_normalized1-linf\n",
      "100: 700.14sec\n",
      "all1_normalized1-l2\n",
      "100: 761.33sec\n",
      "all2_normalized1-l2\n",
      "100: 627.00sec\n",
      "all1_normalized1-l1\n",
      "100: 592.02sec\n",
      "all2_normalized1-l1\n",
      "100: 606.66sec\n",
      "all1_normalized1-linf\n",
      "100: 588.32sec\n",
      "all1_normalized1-l2\n",
      "100: 589.34sec\n",
      "all2_normalized1-l2\n",
      "100: 602.29sec\n",
      "all1_normalized1-l1\n",
      "100: 592.11sec\n",
      "all2_normalized1-l1\n",
      "100: 590.96sec\n",
      "all1_normalized1-linf\n",
      "100: 606.52sec\n",
      "all1_normalized1-l2\n",
      "100: 635.16sec\n",
      "all2_normalized1-l2\n",
      "100: 618.60sec\n",
      "all1_normalized1-l1\n",
      "100: 631.13sec\n",
      "all2_normalized1-l1\n",
      "100: 599.59sec\n",
      "all1_normalized1-linf\n",
      "100: 603.50sec\n",
      "all1_normalized1-l2\n",
      "100: 618.88sec\n",
      "all2_normalized1-l2\n",
      "60: 356.42sec\r"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b51b6fed5f26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{CLUSTER_DIRECTORY}/{nr+1}_{n_clusters}_BioGRID.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkmedoids_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{n_clusters}: {t2-t1:.2f}sec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for run in range(50):\n",
    "    for distance in ['all1_normalized1-linf',\n",
    "                     'all1_normalized1-l2', 'all2_normalized1-l2',\n",
    "                     'all1_normalized1-l1', 'all2_normalized1-l1']:\n",
    "        print(distance)\n",
    "        \n",
    "        CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GCV-G/{distance}/{method}\"\n",
    "        if not os.path.exists(CLUSTER_DIRECTORY):\n",
    "            os.makedirs(CLUSTER_DIRECTORY)\n",
    "            \n",
    "        df = pd.read_csv(f\"{MATRIX_DIRECTORY}/GCV-G/{distance}_BioGRID.txt\", delimiter=' ')\n",
    "        D  = df.values.astype(float) \n",
    "\n",
    "        t1 = time.time()\n",
    "        for n_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS+1):\n",
    "            initial_medoids = sample(range(len(D)), n_clusters)\n",
    "            kmedoids_instance = kmedoids(D, initial_medoids, data_type='distance_matrix')\n",
    "            kmedoids_instance.process()\n",
    "            \n",
    "            nr = get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS)\n",
    "\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{nr+1}_{n_clusters}_BioGRID.txt\", 'w') as f:\n",
    "                for cluster in kmedoids_instance.get_clusters():\n",
    "                    f.write(' '.join(df.columns[cluster]) + '\\n')\n",
    "            t2 = time.time()\n",
    "            print(f'{n_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCV-AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "\n",
    "all_distances = [filename.split('_')[0] for filename in os.listdir(f\"{MATRIX_DIRECTORY}/GCV-AD\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for run in range(50):\n",
    "    for distance in ['all1_normalized1-linf',\n",
    "                     'all1_normalized1-l2', 'all2_normalized1-l2',\n",
    "                     'all1_normalized1-l1', 'all2_normalized1-l1']:\n",
    "        print(distance)\n",
    "        \n",
    "        CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GCV-AD/{distance}/{method}\"\n",
    "        if not os.path.exists(CLUSTER_DIRECTORY):\n",
    "            os.makedirs(CLUSTER_DIRECTORY)\n",
    "            \n",
    "        df = pd.read_csv(f\"{MATRIX_DIRECTORY}/GCV-AD/{distance}_BioGRID.txt\", delimiter=' ')\n",
    "        D  = df.values.astype(float) \n",
    "\n",
    "        t1 = time.time()\n",
    "        for n_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS+1):\n",
    "            initial_medoids = sample(range(len(D)), n_clusters)\n",
    "            kmedoids_instance = kmedoids(D, initial_medoids, data_type='distance_matrix')\n",
    "            kmedoids_instance.process()\n",
    "            \n",
    "            nr = get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS)\n",
    "\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{nr+1}_{n_clusters}_BioGRID.txt\", 'w') as f:\n",
    "                for cluster in kmedoids_instance.get_clusters():\n",
    "                    f.write(' '.join(df.columns[cluster]) + '\\n')\n",
    "            t2 = time.time()\n",
    "            print(f'{n_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCV-DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "\n",
    "all_distances = [filename.split('_')[0] for filename in os.listdir(f\"{MATRIX_DIRECTORY}/GCV-DG\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'kmedoid'\n",
    "\n",
    "for run in range(50):\n",
    "    for distance in ['all1_normalized1-linf',\n",
    "                     'all1_normalized1-l2', 'all2_normalized1-l2',\n",
    "                     'all1_normalized1-l1', 'all2_normalized1-l1']:\n",
    "        print(distance)\n",
    "        \n",
    "        CLUSTER_DIRECTORY = f\"{YEAST_DIRECTORY}/clusterings/GCV-DG/{distance}/{method}\"\n",
    "        if not os.path.exists(CLUSTER_DIRECTORY):\n",
    "            os.makedirs(CLUSTER_DIRECTORY)\n",
    "            \n",
    "        df = pd.read_csv(f\"{MATRIX_DIRECTORY}/GCV-DG/{distance}_BioGRID.txt\", delimiter=' ')\n",
    "        D  = df.values.astype(float) \n",
    "\n",
    "        t1 = time.time()\n",
    "        for n_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS+1):\n",
    "            initial_medoids = sample(range(len(D)), n_clusters)\n",
    "            kmedoids_instance = kmedoids(D, initial_medoids, data_type='distance_matrix')\n",
    "            kmedoids_instance.process()\n",
    "            \n",
    "            nr = get_number_of_pre_runs(CLUSTER_DIRECTORY, distance, MAX_CLUSTERS)\n",
    "\n",
    "            with open(f\"{CLUSTER_DIRECTORY}/{nr+1}_{n_clusters}_BioGRID.txt\", 'w') as f:\n",
    "                for cluster in kmedoids_instance.get_clusters():\n",
    "                    f.write(' '.join(df.columns[cluster]) + '\\n')\n",
    "            t2 = time.time()\n",
    "            print(f'{n_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gGCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 100\n",
    "\n",
    "all_distances = ['normalizedlinf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizedlinf\n",
      "99: 569.67sec\n",
      "normalizedlinf\n",
      "99: 555.84sec\n",
      "normalizedlinf\n",
      "99: 554.14sec\n",
      "normalizedlinf\n",
      "99: 555.52sec\n",
      "normalizedlinf\n",
      "99: 554.21sec\n",
      "normalizedlinf\n",
      "99: 555.25sec\n",
      "normalizedlinf\n",
      "99: 554.59sec\n",
      "normalizedlinf\n",
      "99: 554.19sec\n",
      "normalizedlinf\n",
      "99: 554.66sec\n",
      "normalizedlinf\n",
      "99: 555.05sec\n",
      "normalizedlinf\n",
      "99: 554.81sec\n",
      "normalizedlinf\n",
      "99: 554.58sec\n",
      "normalizedlinf\n",
      "99: 554.33sec\n",
      "normalizedlinf\n",
      "99: 554.85sec\n",
      "normalizedlinf\n",
      "99: 555.31sec\n",
      "normalizedlinf\n",
      "99: 554.66sec\n",
      "normalizedlinf\n",
      "99: 554.98sec\n",
      "normalizedlinf\n",
      "99: 554.77sec\n",
      "normalizedlinf\n",
      "99: 555.27sec\n",
      "normalizedlinf\n",
      "99: 555.33sec\n",
      "normalizedlinf\n",
      "99: 554.48sec\n",
      "normalizedlinf\n",
      "99: 555.08sec\n",
      "normalizedlinf\n",
      "99: 555.41sec\n",
      "normalizedlinf\n",
      "99: 554.54sec\n",
      "normalizedlinf\n",
      "99: 554.56sec\n",
      "normalizedlinf\n",
      "99: 556.31sec\n",
      "normalizedlinf\n",
      "99: 554.94sec\n",
      "normalizedlinf\n",
      "99: 555.55sec\n",
      "normalizedlinf\n",
      "99: 554.78sec\n",
      "normalizedlinf\n",
      "99: 555.50sec\n",
      "normalizedlinf\n",
      "99: 555.09sec\n",
      "normalizedlinf\n",
      "99: 554.69sec\n",
      "normalizedlinf\n",
      "99: 554.88sec\n",
      "normalizedlinf\n",
      "99: 555.27sec\n",
      "normalizedlinf\n",
      "99: 555.07sec\n",
      "normalizedlinf\n",
      "99: 555.76sec\n",
      "normalizedlinf\n",
      "99: 540.33sec\n",
      "normalizedlinf\n",
      "99: 529.24sec\n",
      "normalizedlinf\n",
      "99: 524.44sec\n",
      "normalizedlinf\n",
      "99: 523.82sec\n",
      "normalizedlinf\n",
      "99: 524.23sec\n",
      "normalizedlinf\n",
      "99: 523.94sec\n",
      "normalizedlinf\n",
      "99: 525.23sec\n",
      "normalizedlinf\n",
      "99: 524.44sec\n",
      "normalizedlinf\n",
      "99: 524.37sec\n",
      "normalizedlinf\n",
      "99: 524.98sec\n",
      "normalizedlinf\n",
      "99: 524.53sec\n",
      "normalizedlinf\n",
      "99: 524.52sec\n",
      "normalizedlinf\n",
      "99: 524.31sec\n"
     ]
    }
   ],
   "source": [
    "# Automated\n",
    "for run in range(49):\n",
    "    for distance in all_distances:\n",
    "        print(distance)\n",
    "\n",
    "        if not os.path.exists(f\"{CLUSTERS_DIRECTORY}/gGCV/{distance}\"):\n",
    "            os.makedirs(f\"{CLUSTERS_DIRECTORY}/gGCV/{distance}\")\n",
    "\n",
    "        MATRIX_NAME = f\"sc_BioGRID_gGCV_{distance}\"\n",
    "        with open(f\"{MATRIX_DIRECTORY}/{MATRIX_NAME}.txt\", 'r') as f:\n",
    "            line = f.readline()\n",
    "        D = np.loadtxt(f\"{MATRIX_DIRECTORY}/{MATRIX_NAME}.txt\", skiprows=1)\n",
    "\n",
    "        int2gene = dict(enumerate(line.split()))\n",
    "        \n",
    "        t1 = time.time()\n",
    "        for n_clusters in range(2, 100):\n",
    "            nr = get_number_of_max_runs('gGCV', distance, MAX_CLUSTERS-1) # CAREFULL !!!!!\n",
    "            initial_medoids = sample(range(len(D)), n_clusters)\n",
    "            kmedoids_instance = kmedoids(D, initial_medoids, data_type='distance_matrix')\n",
    "            kmedoids_instance.process()\n",
    "\n",
    "            with open(f\"{CLUSTERS_DIRECTORY}/gGCV/{distance}/{nr+1}_sc_BioGRID_{n_clusters}.txt\", 'w') as f:\n",
    "                for cluster in kmedoids_instance.get_clusters():\n",
    "                    f.write(' '.join(map(int2gene.get,cluster)) + '\\n')\n",
    "            t2 = time.time()\n",
    "            print(f'{n_clusters}: {t2-t1:.2f}sec', end='\\r')\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graco",
   "language": "python",
   "name": "graco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
