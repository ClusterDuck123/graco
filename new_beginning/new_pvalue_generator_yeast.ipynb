{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  --------------------- INPUT PARAMETER AND PATH CLASSES ---------------------\n",
    "# =============================================================================\n",
    "\n",
    "class InputParameters():\n",
    "    RUN   = 0  #sys.argv[1]\n",
    "    RANGE = 10\n",
    "    def __init__(self, network_name, feature, metric, method, aspect):\n",
    "        self.network_name = network_name\n",
    "        self.feature = feature\n",
    "        self.metric  = metric\n",
    "        self.method  = method\n",
    "        self.aspect  = aspect\n",
    "            \n",
    "class Paths():\n",
    "    DATA_DIRECTORY = \"/Users/markusyoussef/Desktop/git/supplements/data\"\n",
    "    RAW_DATA_DIRECTORY = f\"{DATA_DIRECTORY}/raw_data\"\n",
    "    YEAST_DIRECTORY = f\"{DATA_DIRECTORY}/processed_data/yeast\"\n",
    "    NETWORK_DIRECTORY = f\"{YEAST_DIRECTORY}/networks\"\n",
    "    ANNOTATION_DIRECTORY = f\"{YEAST_DIRECTORY}/annotations\"\n",
    "    \n",
    "    def __init__(self, in_parms):\n",
    "        self.NETWORK_FILE    = f\"{self.NETWORK_DIRECTORY}/{in_parms.network_name}.txt\"\n",
    "        self.ANNOTATION_FILE = f\"{self.ANNOTATION_DIRECTORY}/GO_{in_parms.aspect}_systematic_SGD.csv\"\n",
    "        \n",
    "        network_to_method = f\"{in_parms.network_name}/{in_parms.feature}/{in_parms.metric}/{in_parms.method}\"\n",
    "        self.CLUSTER_DIRECTORY = f\"{self.YEAST_DIRECTORY}/clusterings/\"  \\\n",
    "                                 f\"{network_to_method}\"\n",
    "        self.PVALUE_DIRECTORY  = f\"{self.YEAST_DIRECTORY}/pvalues/\"      \\\n",
    "                                 f\"{network_to_method}/{in_parms.aspect}\"\n",
    "    \n",
    "        if not os.path.exists(self.PVALUE_DIRECTORY):\n",
    "            os.makedirs(self.PVALUE_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  -------------------------------- FUNCTIONS ---------------------------------\n",
    "# =============================================================================\n",
    "\n",
    "def get_pvalues(cluster_list, annotation, gene_population):\n",
    "    \"\"\"\n",
    "    Takes a liks of clusters and an annotation file and returns \n",
    "    a dataframe of p-values for each cluster and each annotation term\n",
    "    \"\"\"\n",
    "    \n",
    "    n_clusters = len(cluster_list)\n",
    "\n",
    "# ---------------------------- population size, M -----------------------------\n",
    "    nb_of_annoteted_genes = pd.DataFrame(len(gene_population),\n",
    "                                         index   = annotation.index,\n",
    "                                         columns = range(n_clusters))\n",
    "    \n",
    "# ---------- number of draws (i.e. quantity drawn in each trial), N -----------\n",
    "    n_GOterm_copies_of_cluster_sizes = iter([pd.Series(map(len, cluster_list))]*len(annotation))\n",
    "    size_of_clusters = pd.concat(n_GOterm_copies_of_cluster_sizes, axis=1).T\n",
    "    size_of_clusters.index = annotation.index\n",
    "    \n",
    "# sum of |(annotated) genes in cluster| across all clusters \n",
    "# == |overall (annotated) genes|\n",
    "    assert (size_of_clusters.sum(axis=1) == len(gene_population)).all()\n",
    "\n",
    "# -------------- number of success states in the population, n ----------------\n",
    "    n_cluster_copies_of_annotation_counts = iter([annotation.apply(len)]*n_clusters)\n",
    "    nb_annotated_genes = pd.concat(n_cluster_copies_of_annotation_counts, axis=1)\n",
    "    nb_annotated_genes.columns = range(n_clusters)\n",
    "\n",
    "# --------------------- number of observed successes, k -----------------------\n",
    "    gene_count_of_intersections = (\n",
    "                pd.Series([len(annotated_genes & gene_set) for gene_set in cluster_list])\n",
    "                                     for annotated_genes in annotation)\n",
    "    nb_annotated_genes_in_cluster = pd.concat(gene_count_of_intersections, axis=1).T\n",
    "    nb_annotated_genes_in_cluster.index   = annotation.index\n",
    "    nb_annotated_genes_in_cluster.columns = range(n_clusters)\n",
    "\n",
    "# sum of |annotated genes per GO-term in cluster| across all clusters \n",
    "# == |annotated genes per GO-term|\n",
    "    assert (nb_annotated_genes_in_cluster.sum(axis=1) == annotation.apply(len)).all()\n",
    "    \n",
    "# ------------ all of this just to execute a single scipy function -------------    \n",
    "    return pd.DataFrame(1-hypergeom.cdf(M = nb_of_annoteted_genes.values,\n",
    "                                        N = size_of_clusters.values,\n",
    "                                        n = nb_annotated_genes.values,\n",
    "                                        k = nb_annotated_genes_in_cluster.values-1),\n",
    "                        index=GO2geneset_s.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  ----------------------------------- INIT -----------------------------------\n",
    "# =============================================================================\n",
    "\n",
    "# Global parameters\n",
    "RUN = 0\n",
    "RANGE = 10\n",
    "\n",
    "# Input parameters\n",
    "network_name = 'systematic_PPI_BioGRID'\n",
    "feature = 'GDV'\n",
    "metric  = 'mahalanobis'\n",
    "method  = 'kmedoid'\n",
    "aspect  = 'BP' \n",
    "\n",
    "in_parms = InputParameters(network_name, feature, metric, method, aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network has 5726 genes, of which 1220 (21.31%) are un-annotated.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  ----------------------------------- MAIN -----------------------------------\n",
    "# =============================================================================\n",
    "\n",
    "network_nx = nx.read_edgelist(Paths(in_parms).NETWORK_FILE)\n",
    "annotation_df = pd.read_csv(Paths(in_parms).ANNOTATION_FILE)\n",
    "annotation_df = annotation_df[annotation_df.Systematic_ID.isin(network_nx)]\n",
    "\n",
    "annotated_geneset = set(annotation_df.Systematic_ID)\n",
    "\n",
    "GO2geneset = {go_id: set(genes.Systematic_ID) for go_id, genes in annotation_df.groupby('GO_ID')}\n",
    "gene2GOset = {gene : set(go_ids.GO_ID) for gene, go_ids in annotation_df.groupby('Systematic_ID')}\n",
    "\n",
    "GO2geneset_s = pd.Series(GO2geneset).sort_index()\n",
    "\n",
    "# ------------ unrelated statistics: number of un-annotated genes -------------\n",
    "nb_unannotated_genes = len(network_nx)-len(annotated_geneset)\n",
    "print(f\"Network has {len(network_nx)} genes, of which {nb_unannotated_genes} \" \n",
    "      f\"({100*nb_unannotated_genes/len(network_nx):.2f}%) are un-annotated.\")\n",
    "\n",
    "# ----------------------- this is where the fun starts ------------------------\n",
    "N = len(network_nx)\n",
    "M = int(np.sqrt(N/2))\n",
    "\n",
    "for n_clusters in range(M-RANGE, M+RANGE+1):\n",
    "    with open(f\"{Paths(in_parms).CLUSTER_DIRECTORY}/{RUN}_{n_clusters}.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "\n",
    "# keep only annotated genes in cluster\n",
    "    annotated_cluster_list = [gene_set & annotated_geneset for gene_set in cluster_list]\n",
    "    \n",
    "    pvalues = get_pvalues(cluster_list    = annotated_cluster_list, \n",
    "                          annotation      = GO2geneset_s, \n",
    "                          gene_population = annotated_geneset)\n",
    "\n",
    "# assert that un-annotated genes hava a p-value of 1\n",
    "    for idx, cluster in enumerate(annotated_cluster_list):\n",
    "        if len(cluster) == 0:\n",
    "            assert (pvalues[idx] == 1).all()\n",
    "        else:\n",
    "            indices = set.union(*map(gene2GOset.get, cluster))\n",
    "            assert (pvalues.loc[~pvalues.index.isin(indices)][idx] == 1).all()\n",
    "    \n",
    "    pvalues.to_csv(f\"{Paths(in_parms).PVALUE_DIRECTORY}/{RUN}_{n_clusters}.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graco",
   "language": "python",
   "name": "graco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
