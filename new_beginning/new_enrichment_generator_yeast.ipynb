{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  --------------------- INPUT PARAMETER AND PATH CLASSES ---------------------\n",
    "# =============================================================================\n",
    "\n",
    "class InputParameters():\n",
    "    RUN   = 0  #sys.argv[1]\n",
    "    RANGE = 10\n",
    "    \n",
    "    ALPHA = 0.05\n",
    "    MIN_GO = 5\n",
    "    MAX_GO = 500\n",
    "    MIN_LVL = 0\n",
    "    MAX_LVL = np.inf\n",
    "    CORRECTION = 'BY'\n",
    "    \n",
    "    def __init__(self, network_name, feature, metric, method, aspect):\n",
    "        self.network_name = network_name\n",
    "        self.feature = feature\n",
    "        self.metric  = metric\n",
    "        self.method  = method\n",
    "        self.aspect  = aspect\n",
    "            \n",
    "class Paths():\n",
    "    DATA_DIRECTORY = \"/Users/markusyoussef/Desktop/git/supplements/data\"\n",
    "    RAW_DATA_DIRECTORY = f\"{DATA_DIRECTORY}/raw_data\"\n",
    "    YEAST_DIRECTORY = f\"{DATA_DIRECTORY}/processed_data/yeast\"\n",
    "    NETWORK_DIRECTORY = f\"{YEAST_DIRECTORY}/networks\"\n",
    "    ANNOTATION_DIRECTORY = f\"{YEAST_DIRECTORY}/annotations\"\n",
    "    \n",
    "    def __init__(self, in_parms):\n",
    "        self.NETWORK_FILE    = f\"{self.NETWORK_DIRECTORY}/{in_parms.network_name}.txt\"\n",
    "        self.ANNOTATION_FILE = f\"{self.ANNOTATION_DIRECTORY}/GO_{in_parms.aspect}_systematic_SGD.csv\"\n",
    "        \n",
    "        network_to_method = f\"{in_parms.network_name}/{in_parms.feature}/{in_parms.metric}/{in_parms.method}\"\n",
    "        self.CLUSTER_DIRECTORY    = f\"{self.YEAST_DIRECTORY}/clusterings/\"   \\\n",
    "                                    f\"{network_to_method}\"\n",
    "        self.PVALUE_DIRECTORY     = f\"{self.YEAST_DIRECTORY}/pvalues/\"       \\\n",
    "                                    f\"{network_to_method}/{in_parms.aspect}\"\n",
    "        self.ENRICHMENT_DIRECTORY = f\"{self.YEAST_DIRECTORY}/enrichments/\"   \\\n",
    "                                    f\"{network_to_method}/{in_parms.aspect}/{in_parms.CORRECTION}\"\n",
    "    \n",
    "        if not os.path.exists(self.ENRICHMENT_DIRECTORY):\n",
    "            os.makedirs(self.ENRICHMENT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  -------------------------------- FUNCTIONS --------------------------------\n",
    "# =============================================================================\n",
    "\n",
    "def filter_GOterms(annotation_df):\n",
    "    def lvl_filter(min_lvl = InputParameters.MIN_LVL, \n",
    "                   max_lvl = InputParameters.MAX_LVL):\n",
    "        return annotation_df.Level.between(min_lvl, max_lvl)\n",
    "    def GO_filter(geneset,\n",
    "                  min_GO = InputParameters.MIN_GO, \n",
    "                  max_GO = InputParameters.MAX_GO): \n",
    "        return min_GO <= len(geneset) <= max_GO\n",
    "    \n",
    "    annotation_df = annotation_df[annotation_df.Systematic_ID.isin(network_nx)]\n",
    "    annotation_df = annotation_df[lvl_filter()]\n",
    "    annotation_df = annotation_df.groupby('GO_ID').filter(GO_filter)\n",
    "    \n",
    "    return annotation_df\n",
    "\n",
    "\n",
    "def nb_genes_enriched_in_cluster(cluster_enrichment, cluster, gene2GOset[gene]):\n",
    "        enriched_GOterms = set(cluster_enrichment[cluster_enrichment].index)\n",
    "        \n",
    "        def annotated_in_enriched_term(gene):\n",
    "            return not enriched_GOterms.isdisjoint(gene2GOset[gene])\n",
    "        \n",
    "        return sum(map(annotated_in_enriched_term, cluster))\n",
    "\n",
    "    \n",
    "def get_qvalue_threshold(pvalues, cluster_list, gene2GOset):\n",
    "    correction = InputParameters.CORRECTION\n",
    "    alpha      = InputParameters.ALPHA\n",
    "    # union of gene2GOset across all genes in a cluster\n",
    "    def cluster_to_GOset(cluster):\n",
    "        if len(cluster) == 0:\n",
    "            return list()\n",
    "        else:\n",
    "            return set.union(*map(gene2GOset.get, cluster))\n",
    "\n",
    "    relevant_pvalues = (list(pvalues[idx_cluster][cluster_to_GOset(cluster)])\n",
    "                             for idx_cluster,cluster in enumerate(cluster_list))\n",
    "\n",
    "    sorted_pvalues = sorted(p for pvalues_s in relevant_pvalues for p in pvalues_s)\n",
    "    \n",
    "    m = len(sorted_pvalues) # number of tests\n",
    "    \n",
    "    # (pvalue == 1) <==> (gene is not annotated)\n",
    "    assert (pvalues < 1).values.sum() ==  m\n",
    "    \n",
    "    if   correction == 'Bonferroni': return alpha/m\n",
    "    elif correction == 'BH': c = 1\n",
    "    elif correction == 'BY': c = np.log(m) + np.euler_gamma + 1/(2*m)\n",
    "    else: raise Exception(\"Correction not known!\")\n",
    "        \n",
    "    for k,P_k in enumerate(sorted_pvalues, 1):\n",
    "        if P_k > k/(m*c) * alpha:\n",
    "            # one index shift for starting numeration with 1 \n",
    "            # and another one for because of overshoot in the loop \n",
    "            return sorted_pvalues[k-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  ----------------------------------- INIT -----------------------------------\n",
    "# =============================================================================\n",
    "\n",
    "# Global parameters\n",
    "RUN   = 0\n",
    "RANGE = 10\n",
    "\n",
    "# Input parameters\n",
    "network_name = 'systematic_PPI_BioGRID'\n",
    "feature = 'GDV'\n",
    "metric  = 'mahalanobis'\n",
    "method  = 'kmedoid'\n",
    "aspect  = 'BP' \n",
    "\n",
    "in_parms = InputParameters(network_name, feature, metric, method, aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  ---------------------------------- MAIN -----------------------------------\n",
    "# =============================================================================\n",
    "\n",
    "network_nx = nx.read_edgelist(Paths(in_parms).NETWORK_FILE)\n",
    "annotation_df = pd.read_csv(Paths(in_parms).ANNOTATION_FILE)\n",
    "annotation_df = filter_GOterms(annotation_df)\n",
    "\n",
    "annotated_genes = set(annotation_df.Systematic_ID)\n",
    "filtered_GOset  = set(annotation_df.GO_ID)\n",
    "\n",
    "gene2GOset = {gene : set(go_ids.GO_ID)        for gene, go_ids in annotation_df.groupby('Systematic_ID')}\n",
    "GO2geneset = {go_id: set(genes.Systematic_ID) for go_id, genes in annotation_df.groupby('GO_ID')}\n",
    "\n",
    "GO2geneset_s = pd.Series(GO2geneset).sort_values()\n",
    "\n",
    "cluster_coverages = np.zeros(2*RANGE+1)\n",
    "GO_coverages      = np.zeros(2*RANGE+1)\n",
    "gene_coverages    = np.zeros(2*RANGE+1)\n",
    "    \n",
    "# ----------------------- this is where the fun starts ------------------------\n",
    "N = len(network_nx)\n",
    "M = int(np.sqrt(N/2))\n",
    "\n",
    "for count, n_clusters in enumerate(range(M-RANGE, M+RANGE+1)):\n",
    "    with open(f\"{Paths(in_parms).CLUSTER_DIRECTORY}/{RUN}_{n_clusters}.txt\", 'r') as f:\n",
    "                 cluster_list = [set(line.split()) for line in f]\n",
    "\n",
    "# Keep only annotated genes in cluster\n",
    "    annotated_cluster_list = [geneset & annotated_genes for geneset in cluster_list]\n",
    "\n",
    "    pvalues = pd.read_csv(f\"{Paths(in_parms).PVALUE_DIRECTORY}/{RUN}_{n_clusters}.txt\", \n",
    "                          index_col = 0).loc[filtered_GOset]\n",
    "    pvalues.columns = map(int, pvalues.columns)\n",
    "    \n",
    "    qvalue_th   = get_qvalue_threshold(pvalues, annotated_cluster_list, gene2GOset)\n",
    "    enrichments = pvalues < qvalue_th\n",
    "    \n",
    "    cluster_coverages[count] = sum(enrichments.any(axis=0)) / n_clusters\n",
    "    GO_coverages[     count] = sum(enrichments.any(axis=1)) / len(filtered_GOset)\n",
    "    gene_coverages[   count] = sum(nb_genes_enriched_in_cluster(enrichment_s, \n",
    "                                                                annotated_cluster_list[idx],\n",
    "                                                                gene2GOset[gene]) \n",
    "          for idx, enrichment_s in enrichments.iteritems()) / len(annotated_genes)\n",
    "\n",
    "specs = f\"{RUN}_{M-RANGE}-{M+RANGE}\"\n",
    "np.savetxt(f\"{Paths(in_parms).ENRICHMENT_DIRECTORY}/{specs}_clusters.csv\", cluster_coverages)\n",
    "np.savetxt(f\"{Paths(in_parms).ENRICHMENT_DIRECTORY}/{specs}_GOterms.csv\", GO_coverages)\n",
    "np.savetxt(f\"{Paths(in_parms).ENRICHMENT_DIRECTORY}/{specs}_genes.csv\"   , gene_coverages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graco",
   "language": "python",
   "name": "graco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
